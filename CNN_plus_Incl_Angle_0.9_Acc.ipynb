{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPA/jbpeIg768hNMX2LL8lC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eikeschuett/IcebergShipDetection/blob/DNN_Trial_and_Error/CNN_plus_Incl_Angle_0.9_Acc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp_u7zwvt_jw"
      },
      "source": [
        "import numpy as np # linear algebra\r\n",
        "np.random.seed(666)\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from subprocess import check_output\r\n",
        "from matplotlib import pyplot\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\r\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.layers.merge import Concatenate\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.optimizers import Adam, SGD\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from scipy.ndimage.filters import uniform_filter\r\n",
        "from scipy.ndimage.measurements import variance"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "7nYBzmT4uDBU",
        "outputId": "c1262db1-ab83-4733-a6eb-101db2576234"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive')\r\n",
        "data = pd.read_json('/content/drive/MyDrive/Iceberg_Ship_Classification/train.json')\r\n",
        "\r\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>band_1</th>\n",
              "      <th>band_2</th>\n",
              "      <th>inc_angle</th>\n",
              "      <th>is_iceberg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dfd5f913</td>\n",
              "      <td>[-27.878360999999998, -27.15416, -28.668615, -...</td>\n",
              "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
              "      <td>43.9239</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e25388fd</td>\n",
              "      <td>[-12.242375, -14.920304999999999, -14.920363, ...</td>\n",
              "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
              "      <td>38.1562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>58b2aaa0</td>\n",
              "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
              "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
              "      <td>45.2859</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4cfc3a18</td>\n",
              "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
              "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
              "      <td>43.8306</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>271f93f4</td>\n",
              "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
              "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
              "      <td>35.6256</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... is_iceberg\n",
              "0  dfd5f913  ...          0\n",
              "1  e25388fd  ...          0\n",
              "2  58b2aaa0  ...          1\n",
              "3  4cfc3a18  ...          0\n",
              "4  271f93f4  ...          0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LbOp4V82ZMg"
      },
      "source": [
        "Delete all observations without an inclination angle (133 in total) instead of replacing it with some random values... Then rescale the inclination angle between -1 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiyDkJP5gPwu",
        "outputId": "78c0ee76-696d-4e75-8f56-e52bdf084f16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(data))\r\n",
        "data.inc_angle = data.inc_angle.replace('na', np.nan)\r\n",
        "\r\n",
        "#data.inc_angle = data.inc_angle.astype(float).fillna(0.0)\r\n",
        "data = data.dropna(axis=0, how='any')\r\n",
        "print(len(data))\r\n",
        "print(data.inc_angle.min())\r\n",
        "print(data.inc_angle.max())\r\n",
        "data.inc_angle = 2*(data.inc_angle - 20)/(50-20)-1\r\n",
        "print(data.inc_angle.min())\r\n",
        "print(data.inc_angle.max())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1604\n",
            "1471\n",
            "24.7546\n",
            "45.9375\n",
            "-0.6830266666666667\n",
            "0.7291666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzAKZG0RuZ2b"
      },
      "source": [
        "def lee_filter(img, size):\r\n",
        "    # From here: https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\r\n",
        "    img_mean = uniform_filter(img, (size, size))\r\n",
        "    img_sqr_mean = uniform_filter(img**2, (size, size))\r\n",
        "    img_variance = img_sqr_mean - img_mean**2\r\n",
        "\r\n",
        "    overall_variance = variance(img)\r\n",
        "\r\n",
        "    img_weights = img_variance / (img_variance + overall_variance)\r\n",
        "    img_output = img_mean + img_weights * (img - img_mean)\r\n",
        "    return img_output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqww4ARyuabj"
      },
      "source": [
        "def prepare_data(data):\r\n",
        "  x_angle = np.array(data[\"inc_angle\"])\r\n",
        "\r\n",
        "  # Get the labels (y-values)\r\n",
        "  labels = np.array(data[\"is_iceberg\"])\r\n",
        "\r\n",
        "  # Create empty list for the images\r\n",
        "  imgs = []\r\n",
        "  for i, row in data.iterrows():\r\n",
        "      # Reshape list to image\r\n",
        "      hh  = np.reshape(row[\"band_1\"], (75, 75))\r\n",
        "      hv  = np.reshape(row[\"band_2\"], (75, 75))\r\n",
        "      b3  = hh + hv\r\n",
        "\r\n",
        "      hh = lee_filter(hh, 20)\r\n",
        "      hv = lee_filter(hv, 20)\r\n",
        "      b3 = lee_filter(b3, 20)      \r\n",
        "        \r\n",
        "      # Rescale images between 0 and 1 for faster convergence rate\r\n",
        "      hh = (hh - hh.min())/(hh.max()-hh.min())\r\n",
        "      hv = (hv - hv.min())/(hv.max()-hv.min())\r\n",
        "      b3 = (b3 - b3.min())/(b3.max()-b3.min())      \r\n",
        "\r\n",
        "      # Stack the bands and append them to imgs\r\n",
        "      imgs.append(np.dstack((hh, hv, b3)))\r\n",
        "      \r\n",
        "  # Split dataset into training (70%)  and validation (30 %)\r\n",
        "  x_train, x_val, x_angle_train, x_angle_val, y_train, y_val = train_test_split(imgs, \r\n",
        "                                                    x_angle,\r\n",
        "                                                    labels, \r\n",
        "                                                    test_size=0.3, \r\n",
        "                                                    random_state=0)\r\n",
        "  # Then split validation dataset into validation (20 %) and testing (10 %)\r\n",
        "  x_val, x_test, x_angle_val, x_angle_test, y_val, y_test = train_test_split(x_val,\r\n",
        "                                                  x_angle_val,\r\n",
        "                                                  y_val,\r\n",
        "                                                  test_size=(1/3),\r\n",
        "                                                  random_state=0)\r\n",
        "\r\n",
        "  x_train = np.array(x_train)\r\n",
        "  x_test = np.array(x_test)\r\n",
        "  x_val = np.array(x_val)\r\n",
        "  x_angle_test = np.array(x_angle_test)\r\n",
        "  x_angle_train = np.array(x_angle_train)\r\n",
        "  x_angle_val = np.array(x_angle_val)\r\n",
        "  return x_train, x_val, x_test, x_angle_train, x_angle_val, x_angle_test, y_train, y_val, y_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28CxgXc60t2u",
        "outputId": "c5a5892b-9a95-47d7-b1bd-8eef141a085b"
      },
      "source": [
        "x_train, x_val, x_test, x_angle_train, x_angle_val, x_angle_test, y_train, y_val, y_test = prepare_data(data)\r\n",
        "print(\"Number of samples for training: \" + str(len(x_train)) + \" (\" + str(round(len(x_train)/len(data), 4)*100) + \" %)\")\r\n",
        "print(\"Number of samples for validation: \" + str(len(x_val)) + \" (\" + str(round(len(x_val)/len(data), 4)*100) + \" %)\")\r\n",
        "print(\"Number of samples for testing: \" + str(len(x_test)) + \" (\" + str(round(len(x_test)/len(data), 4)*100) + \" %)\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples for training: 1029 (69.95 %)\n",
            "Number of samples for validation: 294 (19.99 %)\n",
            "Number of samples for testing: 148 (10.059999999999999 %)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oezdQAC3Zx_"
      },
      "source": [
        "Create two data generators for both images and the inclination angle and combine them. I have the code from https://www.kaggle.com/sinkie/keras-data-augmentation-with-multiple-inputs, but still don't understand what this is doing exactly..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-_w43W5M60A"
      },
      "source": [
        "# From here: https://www.kaggle.com/sinkie/keras-data-augmentation-with-multiple-inputs\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "gen = ImageDataGenerator(\r\n",
        "      rotation_range = 45,\r\n",
        "      width_shift_range = 0.15,\r\n",
        "      height_shift_range = 0.15,\r\n",
        "      shear_range = 0.15,\r\n",
        "      zoom_range = 0.15,\r\n",
        "      horizontal_flip = True,\r\n",
        "      vertical_flip = True,\r\n",
        "      fill_mode = 'nearest')\r\n",
        "\r\n",
        "# Here is the function that merges our two generators\r\n",
        "# We use the exact same generator with the same random seed for both the y and angle arrays\r\n",
        "def gen_flow_for_two_inputs(X1, X2, y):\r\n",
        "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=666)\r\n",
        "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=666)\r\n",
        "    while True:\r\n",
        "            X1i = genX1.next()\r\n",
        "            X2i = genX2.next()\r\n",
        "            #Assert arrays are equal - this was for peace of mind, but slows down training\r\n",
        "            #np.testing.assert_array_equal(X1i[0],X2i[0])\r\n",
        "            yield [X1i[0], X2i[1]], X1i[1]\r\n",
        "\r\n",
        "# Finally create generator\r\n",
        "gen_flow = gen_flow_for_two_inputs(x_train, x_angle_train, y_train)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b32oC96X1c1M"
      },
      "source": [
        "# train_generator, val_generator = DataGenerators(x_train, x_val, y_train, y_val)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVC3fO7Hw5Uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8525cd6-cdf3-4795-8d7e-8d00987b36d4"
      },
      "source": [
        "def create_model(optimizer):\r\n",
        "  ac_fct      = \"relu\"\r\n",
        "  #momentum    = 0\r\n",
        "\r\n",
        "  input_img   = Input(shape=(75, 75 ,3), name=\"X_img\")\r\n",
        "  input_angle = Input(shape=[1], name=\"angle\")\r\n",
        "\r\n",
        "  #cnn = BatchNormalization()(input_img)\r\n",
        "  cnn = Conv2D(16, kernel_size=(3,3), activation = \"relu\")(input_img)\r\n",
        "  cnn = Conv2D(16, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  cnn = MaxPooling2D((2,2))(cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)\r\n",
        "\r\n",
        "  cnn = Conv2D(32, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  #cnn = Conv2D(32, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  cnn = MaxPooling2D((2,2)) (cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)\r\n",
        "\r\n",
        "  cnn = Conv2D(64, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  #cnn = Conv2D(64, kernel_size=(3,3), activation = \"relu\") (cnn)\r\n",
        "  cnn = MaxPooling2D((2,2)) (cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)  \r\n",
        "\r\n",
        "  cnn = Conv2D(128, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  cnn = Conv2D(128, kernel_size=(3,3), activation = \"relu\") (cnn)\r\n",
        "  cnn = MaxPooling2D((2,2)) (cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)  \r\n",
        "  \r\n",
        "\r\n",
        "  cnn = GlobalMaxPooling2D() (cnn)\r\n",
        "\r\n",
        "  #angle = BatchNormalization(momentum=0)(input_angle)\r\n",
        "\r\n",
        "  concat = (Concatenate()([cnn, input_angle]))\r\n",
        "\r\n",
        "  dense = Dense(32, activation=\"relu\") (concat)\r\n",
        "  # dense = BatchNormalization() (dense)\r\n",
        "  # dense = Dropout(0.2)(dense)\r\n",
        "  \r\n",
        "  #dense = Dense(128, activation=\"relu\") (dense)\r\n",
        "  #dense = BatchNormalization() (dense)\r\n",
        "  #dense = Dropout(0.2)(dense)\r\n",
        "\r\n",
        "  #dense = Dense(128, activation=\"relu\") (dense)\r\n",
        "  #dense = BatchNormalization() (dense)\r\n",
        "  #dense = Dropout(0.2)(dense)\r\n",
        "\r\n",
        "  output = Dense(1, activation=\"sigmoid\")(dense)\r\n",
        "\r\n",
        "  model = Model([input_img, input_angle], output)\r\n",
        "  #optimizer = Adam(lr=0.1, epsilon=1e-08, decay=0.0)\r\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\r\n",
        "  return model\r\n",
        "\r\n",
        "epochs = 250\r\n",
        "# learning_rate = 0.1\r\n",
        "# decay_rate = learning_rate / epochs\r\n",
        "# momentum = 0.8\r\n",
        "# sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\r\n",
        "\r\n",
        "# from keras.optimizers import Adadelta\r\n",
        "model = create_model(optimizer = Adam())\r\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "X_img (InputLayer)              [(None, 75, 75, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 73, 73, 16)   448         X_img[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 71, 71, 16)   2320        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 16)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 35, 35, 16)   0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 33, 33, 32)   4640        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 16, 16, 32)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 14, 14, 64)   18496       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 64)     0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 64)     0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 5, 5, 128)    73856       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 3, 3, 128)    147584      conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1, 1, 128)    0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 128)          0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "angle (InputLayer)              [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 129)          0           global_max_pooling2d[0][0]       \n",
            "                                                                 angle[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           4160        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 251,537\n",
            "Trainable params: 251,537\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpDHGNPh1KSV"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJbwtdGeNO02",
        "outputId": "9b460019-a5c4-495b-cc2b-57ec554222d4"
      },
      "source": [
        "history = model.fit(gen_flow, validation_data=([x_val, x_angle_val], y_val),\r\n",
        "                    steps_per_epoch=len(x_train) / batch_size, epochs=epochs)\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "32/32 [==============================] - 7s 119ms/step - loss: 0.6944 - accuracy: 0.4990 - val_loss: 0.6855 - val_accuracy: 0.5306\n",
            "Epoch 2/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.6804 - accuracy: 0.6111 - val_loss: 0.7265 - val_accuracy: 0.5680\n",
            "Epoch 3/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.6710 - accuracy: 0.6360 - val_loss: 0.6458 - val_accuracy: 0.6122\n",
            "Epoch 4/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.6136 - accuracy: 0.6707 - val_loss: 0.5886 - val_accuracy: 0.6599\n",
            "Epoch 5/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.5909 - accuracy: 0.6953 - val_loss: 0.5543 - val_accuracy: 0.7109\n",
            "Epoch 6/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.5771 - accuracy: 0.6919 - val_loss: 0.5306 - val_accuracy: 0.7177\n",
            "Epoch 7/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.5596 - accuracy: 0.7024 - val_loss: 0.5329 - val_accuracy: 0.7245\n",
            "Epoch 8/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.5288 - accuracy: 0.7432 - val_loss: 0.5382 - val_accuracy: 0.6735\n",
            "Epoch 9/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.5677 - accuracy: 0.6872 - val_loss: 0.5012 - val_accuracy: 0.7313\n",
            "Epoch 10/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.5135 - accuracy: 0.7394 - val_loss: 0.5753 - val_accuracy: 0.6735\n",
            "Epoch 11/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.5368 - accuracy: 0.7190 - val_loss: 0.4604 - val_accuracy: 0.7619\n",
            "Epoch 12/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.4831 - accuracy: 0.7431 - val_loss: 0.4318 - val_accuracy: 0.7721\n",
            "Epoch 13/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.5245 - accuracy: 0.7276 - val_loss: 0.4454 - val_accuracy: 0.7653\n",
            "Epoch 14/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.4510 - accuracy: 0.7774 - val_loss: 0.3887 - val_accuracy: 0.8197\n",
            "Epoch 15/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.4526 - accuracy: 0.7856 - val_loss: 0.5166 - val_accuracy: 0.7619\n",
            "Epoch 16/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.4706 - accuracy: 0.7465 - val_loss: 0.3901 - val_accuracy: 0.8163\n",
            "Epoch 17/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.4328 - accuracy: 0.8027 - val_loss: 0.3483 - val_accuracy: 0.8401\n",
            "Epoch 18/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3790 - accuracy: 0.7876 - val_loss: 0.3938 - val_accuracy: 0.8095\n",
            "Epoch 19/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.4451 - accuracy: 0.7892 - val_loss: 0.3542 - val_accuracy: 0.8401\n",
            "Epoch 20/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3947 - accuracy: 0.8093 - val_loss: 0.3694 - val_accuracy: 0.8299\n",
            "Epoch 21/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.4203 - accuracy: 0.7921 - val_loss: 0.3235 - val_accuracy: 0.8537\n",
            "Epoch 22/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.4095 - accuracy: 0.8110 - val_loss: 0.3266 - val_accuracy: 0.8571\n",
            "Epoch 23/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3675 - accuracy: 0.8262 - val_loss: 0.3210 - val_accuracy: 0.8537\n",
            "Epoch 24/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3871 - accuracy: 0.8088 - val_loss: 0.3387 - val_accuracy: 0.8503\n",
            "Epoch 25/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3965 - accuracy: 0.8158 - val_loss: 0.3286 - val_accuracy: 0.8537\n",
            "Epoch 26/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3603 - accuracy: 0.8468 - val_loss: 0.3764 - val_accuracy: 0.8197\n",
            "Epoch 27/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3935 - accuracy: 0.8125 - val_loss: 0.3198 - val_accuracy: 0.8571\n",
            "Epoch 28/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3815 - accuracy: 0.8166 - val_loss: 0.3092 - val_accuracy: 0.8741\n",
            "Epoch 29/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3624 - accuracy: 0.8319 - val_loss: 0.3098 - val_accuracy: 0.8707\n",
            "Epoch 30/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3947 - accuracy: 0.8120 - val_loss: 0.3291 - val_accuracy: 0.8639\n",
            "Epoch 31/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3700 - accuracy: 0.8196 - val_loss: 0.3405 - val_accuracy: 0.8537\n",
            "Epoch 32/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3698 - accuracy: 0.8093 - val_loss: 0.3102 - val_accuracy: 0.8673\n",
            "Epoch 33/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3928 - accuracy: 0.7982 - val_loss: 0.3289 - val_accuracy: 0.8571\n",
            "Epoch 34/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3620 - accuracy: 0.8305 - val_loss: 0.3403 - val_accuracy: 0.8469\n",
            "Epoch 35/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3681 - accuracy: 0.8322 - val_loss: 0.3171 - val_accuracy: 0.8571\n",
            "Epoch 36/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3541 - accuracy: 0.8223 - val_loss: 0.4298 - val_accuracy: 0.8129\n",
            "Epoch 37/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.4200 - accuracy: 0.7941 - val_loss: 0.3268 - val_accuracy: 0.8639\n",
            "Epoch 38/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3707 - accuracy: 0.8289 - val_loss: 0.3202 - val_accuracy: 0.8639\n",
            "Epoch 39/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3563 - accuracy: 0.8273 - val_loss: 0.3275 - val_accuracy: 0.8503\n",
            "Epoch 40/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3837 - accuracy: 0.8145 - val_loss: 0.3155 - val_accuracy: 0.8639\n",
            "Epoch 41/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3893 - accuracy: 0.8059 - val_loss: 0.3333 - val_accuracy: 0.8503\n",
            "Epoch 42/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3703 - accuracy: 0.8414 - val_loss: 0.3977 - val_accuracy: 0.8163\n",
            "Epoch 43/250\n",
            "32/32 [==============================] - 3s 104ms/step - loss: 0.3851 - accuracy: 0.8035 - val_loss: 0.3567 - val_accuracy: 0.8367\n",
            "Epoch 44/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3515 - accuracy: 0.8243 - val_loss: 0.3401 - val_accuracy: 0.8605\n",
            "Epoch 45/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3413 - accuracy: 0.8439 - val_loss: 0.3133 - val_accuracy: 0.8571\n",
            "Epoch 46/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3471 - accuracy: 0.8365 - val_loss: 0.3145 - val_accuracy: 0.8673\n",
            "Epoch 47/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3696 - accuracy: 0.8196 - val_loss: 0.3138 - val_accuracy: 0.8639\n",
            "Epoch 48/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3699 - accuracy: 0.8259 - val_loss: 0.4202 - val_accuracy: 0.8163\n",
            "Epoch 49/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.4444 - accuracy: 0.8003 - val_loss: 0.3541 - val_accuracy: 0.8367\n",
            "Epoch 50/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3891 - accuracy: 0.8030 - val_loss: 0.3204 - val_accuracy: 0.8605\n",
            "Epoch 51/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3427 - accuracy: 0.8317 - val_loss: 0.3019 - val_accuracy: 0.8741\n",
            "Epoch 52/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3433 - accuracy: 0.8371 - val_loss: 0.2983 - val_accuracy: 0.8776\n",
            "Epoch 53/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3312 - accuracy: 0.8290 - val_loss: 0.3088 - val_accuracy: 0.8673\n",
            "Epoch 54/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3572 - accuracy: 0.8239 - val_loss: 0.3096 - val_accuracy: 0.8810\n",
            "Epoch 55/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3481 - accuracy: 0.8380 - val_loss: 0.3099 - val_accuracy: 0.8571\n",
            "Epoch 56/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3464 - accuracy: 0.8488 - val_loss: 0.2950 - val_accuracy: 0.8707\n",
            "Epoch 57/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3564 - accuracy: 0.8329 - val_loss: 0.3253 - val_accuracy: 0.8537\n",
            "Epoch 58/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3479 - accuracy: 0.8261 - val_loss: 0.2933 - val_accuracy: 0.8741\n",
            "Epoch 59/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3146 - accuracy: 0.8600 - val_loss: 0.3423 - val_accuracy: 0.8707\n",
            "Epoch 60/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3852 - accuracy: 0.8256 - val_loss: 0.3274 - val_accuracy: 0.8639\n",
            "Epoch 61/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.4124 - accuracy: 0.8129 - val_loss: 0.2924 - val_accuracy: 0.8673\n",
            "Epoch 62/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3477 - accuracy: 0.8323 - val_loss: 0.3152 - val_accuracy: 0.8537\n",
            "Epoch 63/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3142 - accuracy: 0.8543 - val_loss: 0.3241 - val_accuracy: 0.8707\n",
            "Epoch 64/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3637 - accuracy: 0.8128 - val_loss: 0.3296 - val_accuracy: 0.8605\n",
            "Epoch 65/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3440 - accuracy: 0.8378 - val_loss: 0.2972 - val_accuracy: 0.8776\n",
            "Epoch 66/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3566 - accuracy: 0.8237 - val_loss: 0.3058 - val_accuracy: 0.8741\n",
            "Epoch 67/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3246 - accuracy: 0.8487 - val_loss: 0.5221 - val_accuracy: 0.7789\n",
            "Epoch 68/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.4212 - accuracy: 0.8018 - val_loss: 0.3121 - val_accuracy: 0.8707\n",
            "Epoch 69/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.4046 - accuracy: 0.8158 - val_loss: 0.3160 - val_accuracy: 0.8707\n",
            "Epoch 70/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3414 - accuracy: 0.8406 - val_loss: 0.2893 - val_accuracy: 0.8673\n",
            "Epoch 71/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3576 - accuracy: 0.8218 - val_loss: 0.2986 - val_accuracy: 0.8878\n",
            "Epoch 72/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3452 - accuracy: 0.8572 - val_loss: 0.3259 - val_accuracy: 0.8605\n",
            "Epoch 73/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3476 - accuracy: 0.8394 - val_loss: 0.3119 - val_accuracy: 0.8707\n",
            "Epoch 74/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3315 - accuracy: 0.8461 - val_loss: 0.3241 - val_accuracy: 0.8605\n",
            "Epoch 75/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3328 - accuracy: 0.8531 - val_loss: 0.3182 - val_accuracy: 0.8673\n",
            "Epoch 76/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3214 - accuracy: 0.8529 - val_loss: 0.3070 - val_accuracy: 0.8810\n",
            "Epoch 77/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3249 - accuracy: 0.8473 - val_loss: 0.3185 - val_accuracy: 0.8639\n",
            "Epoch 78/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3314 - accuracy: 0.8302 - val_loss: 0.2881 - val_accuracy: 0.8776\n",
            "Epoch 79/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3032 - accuracy: 0.8507 - val_loss: 0.3326 - val_accuracy: 0.8741\n",
            "Epoch 80/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3472 - accuracy: 0.8278 - val_loss: 0.3037 - val_accuracy: 0.8810\n",
            "Epoch 81/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3241 - accuracy: 0.8577 - val_loss: 0.2808 - val_accuracy: 0.8810\n",
            "Epoch 82/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3435 - accuracy: 0.8334 - val_loss: 0.2928 - val_accuracy: 0.8878\n",
            "Epoch 83/250\n",
            "32/32 [==============================] - 3s 100ms/step - loss: 0.3953 - accuracy: 0.8137 - val_loss: 0.2834 - val_accuracy: 0.8776\n",
            "Epoch 84/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2974 - accuracy: 0.8451 - val_loss: 0.3048 - val_accuracy: 0.8776\n",
            "Epoch 85/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3415 - accuracy: 0.8311 - val_loss: 0.2852 - val_accuracy: 0.8844\n",
            "Epoch 86/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3283 - accuracy: 0.8527 - val_loss: 0.2833 - val_accuracy: 0.8707\n",
            "Epoch 87/250\n",
            "32/32 [==============================] - 3s 104ms/step - loss: 0.3498 - accuracy: 0.8390 - val_loss: 0.3408 - val_accuracy: 0.8401\n",
            "Epoch 88/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3370 - accuracy: 0.8451 - val_loss: 0.2852 - val_accuracy: 0.8810\n",
            "Epoch 89/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2960 - accuracy: 0.8571 - val_loss: 0.2855 - val_accuracy: 0.8844\n",
            "Epoch 90/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3210 - accuracy: 0.8497 - val_loss: 0.2975 - val_accuracy: 0.8741\n",
            "Epoch 91/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3005 - accuracy: 0.8477 - val_loss: 0.3146 - val_accuracy: 0.8605\n",
            "Epoch 92/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3090 - accuracy: 0.8388 - val_loss: 0.3249 - val_accuracy: 0.8741\n",
            "Epoch 93/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3210 - accuracy: 0.8529 - val_loss: 0.3287 - val_accuracy: 0.8810\n",
            "Epoch 94/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3252 - accuracy: 0.8386 - val_loss: 0.2980 - val_accuracy: 0.8810\n",
            "Epoch 95/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3190 - accuracy: 0.8510 - val_loss: 0.3823 - val_accuracy: 0.8299\n",
            "Epoch 96/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3347 - accuracy: 0.8327 - val_loss: 0.2929 - val_accuracy: 0.8741\n",
            "Epoch 97/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3090 - accuracy: 0.8614 - val_loss: 0.3030 - val_accuracy: 0.8707\n",
            "Epoch 98/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3006 - accuracy: 0.8607 - val_loss: 0.3104 - val_accuracy: 0.8878\n",
            "Epoch 99/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2955 - accuracy: 0.8708 - val_loss: 0.2947 - val_accuracy: 0.8844\n",
            "Epoch 100/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3197 - accuracy: 0.8565 - val_loss: 0.3428 - val_accuracy: 0.8639\n",
            "Epoch 101/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3089 - accuracy: 0.8581 - val_loss: 0.2794 - val_accuracy: 0.8878\n",
            "Epoch 102/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3516 - accuracy: 0.8527 - val_loss: 0.2789 - val_accuracy: 0.8810\n",
            "Epoch 103/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3328 - accuracy: 0.8399 - val_loss: 0.3079 - val_accuracy: 0.8776\n",
            "Epoch 104/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3074 - accuracy: 0.8746 - val_loss: 0.3582 - val_accuracy: 0.8469\n",
            "Epoch 105/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3545 - accuracy: 0.8475 - val_loss: 0.2930 - val_accuracy: 0.8844\n",
            "Epoch 106/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3215 - accuracy: 0.8323 - val_loss: 0.3024 - val_accuracy: 0.8707\n",
            "Epoch 107/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3775 - accuracy: 0.8195 - val_loss: 0.3220 - val_accuracy: 0.8741\n",
            "Epoch 108/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3410 - accuracy: 0.8681 - val_loss: 0.2822 - val_accuracy: 0.8844\n",
            "Epoch 109/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3296 - accuracy: 0.8325 - val_loss: 0.2875 - val_accuracy: 0.8810\n",
            "Epoch 110/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3188 - accuracy: 0.8536 - val_loss: 0.2992 - val_accuracy: 0.9048\n",
            "Epoch 111/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2816 - accuracy: 0.8653 - val_loss: 0.2952 - val_accuracy: 0.8776\n",
            "Epoch 112/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3219 - accuracy: 0.8510 - val_loss: 0.3167 - val_accuracy: 0.8673\n",
            "Epoch 113/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3318 - accuracy: 0.8403 - val_loss: 0.3065 - val_accuracy: 0.8844\n",
            "Epoch 114/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3557 - accuracy: 0.8462 - val_loss: 0.3300 - val_accuracy: 0.8741\n",
            "Epoch 115/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3104 - accuracy: 0.8501 - val_loss: 0.3809 - val_accuracy: 0.8401\n",
            "Epoch 116/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3744 - accuracy: 0.8362 - val_loss: 0.2823 - val_accuracy: 0.8878\n",
            "Epoch 117/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3345 - accuracy: 0.8345 - val_loss: 0.3152 - val_accuracy: 0.8810\n",
            "Epoch 118/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3040 - accuracy: 0.8586 - val_loss: 0.3123 - val_accuracy: 0.8776\n",
            "Epoch 119/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3460 - accuracy: 0.8468 - val_loss: 0.2978 - val_accuracy: 0.8912\n",
            "Epoch 120/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3067 - accuracy: 0.8668 - val_loss: 0.2743 - val_accuracy: 0.9082\n",
            "Epoch 121/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2702 - accuracy: 0.8778 - val_loss: 0.2898 - val_accuracy: 0.8912\n",
            "Epoch 122/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3338 - accuracy: 0.8445 - val_loss: 0.2840 - val_accuracy: 0.8946\n",
            "Epoch 123/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.2679 - accuracy: 0.8797 - val_loss: 0.2946 - val_accuracy: 0.8878\n",
            "Epoch 124/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2983 - accuracy: 0.8702 - val_loss: 0.2956 - val_accuracy: 0.8878\n",
            "Epoch 125/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3064 - accuracy: 0.8621 - val_loss: 0.3043 - val_accuracy: 0.8844\n",
            "Epoch 126/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3114 - accuracy: 0.8525 - val_loss: 0.2940 - val_accuracy: 0.8946\n",
            "Epoch 127/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3035 - accuracy: 0.8615 - val_loss: 0.2813 - val_accuracy: 0.8878\n",
            "Epoch 128/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2464 - accuracy: 0.9057 - val_loss: 0.3068 - val_accuracy: 0.8946\n",
            "Epoch 129/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.2809 - accuracy: 0.8577 - val_loss: 0.2889 - val_accuracy: 0.8878\n",
            "Epoch 130/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3091 - accuracy: 0.8521 - val_loss: 0.3082 - val_accuracy: 0.8946\n",
            "Epoch 131/250\n",
            "32/32 [==============================] - 3s 106ms/step - loss: 0.2753 - accuracy: 0.8647 - val_loss: 0.3029 - val_accuracy: 0.8946\n",
            "Epoch 132/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3022 - accuracy: 0.8557 - val_loss: 0.2804 - val_accuracy: 0.8912\n",
            "Epoch 133/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.2977 - accuracy: 0.8555 - val_loss: 0.2591 - val_accuracy: 0.8946\n",
            "Epoch 134/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2895 - accuracy: 0.8740 - val_loss: 0.2741 - val_accuracy: 0.8946\n",
            "Epoch 135/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3246 - accuracy: 0.8611 - val_loss: 0.2626 - val_accuracy: 0.9014\n",
            "Epoch 136/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3142 - accuracy: 0.8484 - val_loss: 0.3252 - val_accuracy: 0.8741\n",
            "Epoch 137/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3492 - accuracy: 0.8300 - val_loss: 0.2804 - val_accuracy: 0.8912\n",
            "Epoch 138/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.2976 - accuracy: 0.8636 - val_loss: 0.3295 - val_accuracy: 0.8946\n",
            "Epoch 139/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2721 - accuracy: 0.8846 - val_loss: 0.3211 - val_accuracy: 0.8435\n",
            "Epoch 140/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3074 - accuracy: 0.8461 - val_loss: 0.2932 - val_accuracy: 0.8980\n",
            "Epoch 141/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3079 - accuracy: 0.8580 - val_loss: 0.2878 - val_accuracy: 0.8980\n",
            "Epoch 142/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2861 - accuracy: 0.8823 - val_loss: 0.3106 - val_accuracy: 0.8810\n",
            "Epoch 143/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3161 - accuracy: 0.8416 - val_loss: 0.3067 - val_accuracy: 0.8946\n",
            "Epoch 144/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3312 - accuracy: 0.8607 - val_loss: 0.2898 - val_accuracy: 0.8844\n",
            "Epoch 145/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3213 - accuracy: 0.8427 - val_loss: 0.2954 - val_accuracy: 0.9014\n",
            "Epoch 146/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3155 - accuracy: 0.8687 - val_loss: 0.2875 - val_accuracy: 0.8980\n",
            "Epoch 147/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2978 - accuracy: 0.8622 - val_loss: 0.2861 - val_accuracy: 0.9082\n",
            "Epoch 148/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2924 - accuracy: 0.8706 - val_loss: 0.2871 - val_accuracy: 0.8946\n",
            "Epoch 149/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2981 - accuracy: 0.8754 - val_loss: 0.2947 - val_accuracy: 0.9014\n",
            "Epoch 150/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2563 - accuracy: 0.8941 - val_loss: 0.2951 - val_accuracy: 0.9116\n",
            "Epoch 151/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2736 - accuracy: 0.8623 - val_loss: 0.3037 - val_accuracy: 0.8810\n",
            "Epoch 152/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2718 - accuracy: 0.8901 - val_loss: 0.2714 - val_accuracy: 0.8878\n",
            "Epoch 153/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3086 - accuracy: 0.8692 - val_loss: 0.2639 - val_accuracy: 0.8878\n",
            "Epoch 154/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2941 - accuracy: 0.8667 - val_loss: 0.2774 - val_accuracy: 0.8980\n",
            "Epoch 155/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2853 - accuracy: 0.8874 - val_loss: 0.2981 - val_accuracy: 0.8946\n",
            "Epoch 156/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3192 - accuracy: 0.8505 - val_loss: 0.3006 - val_accuracy: 0.8878\n",
            "Epoch 157/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2804 - accuracy: 0.8756 - val_loss: 0.2995 - val_accuracy: 0.8776\n",
            "Epoch 158/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2859 - accuracy: 0.8709 - val_loss: 0.2704 - val_accuracy: 0.9252\n",
            "Epoch 159/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.2943 - accuracy: 0.8558 - val_loss: 0.2752 - val_accuracy: 0.8810\n",
            "Epoch 160/250\n",
            "32/32 [==============================] - 3s 101ms/step - loss: 0.3344 - accuracy: 0.8554 - val_loss: 0.2944 - val_accuracy: 0.8741\n",
            "Epoch 161/250\n",
            "32/32 [==============================] - 3s 104ms/step - loss: 0.3097 - accuracy: 0.8566 - val_loss: 0.2986 - val_accuracy: 0.8810\n",
            "Epoch 162/250\n",
            "32/32 [==============================] - 3s 100ms/step - loss: 0.2821 - accuracy: 0.8639 - val_loss: 0.3177 - val_accuracy: 0.8844\n",
            "Epoch 163/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.2655 - accuracy: 0.8865 - val_loss: 0.2996 - val_accuracy: 0.9116\n",
            "Epoch 164/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3048 - accuracy: 0.8482 - val_loss: 0.2893 - val_accuracy: 0.8946\n",
            "Epoch 165/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2864 - accuracy: 0.8661 - val_loss: 0.3008 - val_accuracy: 0.8912\n",
            "Epoch 166/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2543 - accuracy: 0.8843 - val_loss: 0.3149 - val_accuracy: 0.9048\n",
            "Epoch 167/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2810 - accuracy: 0.8814 - val_loss: 0.2930 - val_accuracy: 0.8946\n",
            "Epoch 168/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2698 - accuracy: 0.8811 - val_loss: 0.2934 - val_accuracy: 0.8980\n",
            "Epoch 169/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2832 - accuracy: 0.8694 - val_loss: 0.2935 - val_accuracy: 0.8912\n",
            "Epoch 170/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2798 - accuracy: 0.8587 - val_loss: 0.3180 - val_accuracy: 0.8776\n",
            "Epoch 171/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3160 - accuracy: 0.8556 - val_loss: 0.3129 - val_accuracy: 0.8741\n",
            "Epoch 172/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2811 - accuracy: 0.8614 - val_loss: 0.2827 - val_accuracy: 0.8980\n",
            "Epoch 173/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3131 - accuracy: 0.8599 - val_loss: 0.3303 - val_accuracy: 0.8912\n",
            "Epoch 174/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3166 - accuracy: 0.8603 - val_loss: 0.2830 - val_accuracy: 0.8946\n",
            "Epoch 175/250\n",
            "32/32 [==============================] - 3s 105ms/step - loss: 0.2899 - accuracy: 0.8652 - val_loss: 0.3244 - val_accuracy: 0.8878\n",
            "Epoch 176/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3402 - accuracy: 0.8582 - val_loss: 0.2785 - val_accuracy: 0.8810\n",
            "Epoch 177/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2726 - accuracy: 0.8751 - val_loss: 0.2839 - val_accuracy: 0.8844\n",
            "Epoch 178/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2666 - accuracy: 0.8896 - val_loss: 0.2983 - val_accuracy: 0.8878\n",
            "Epoch 179/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2979 - accuracy: 0.8697 - val_loss: 0.3034 - val_accuracy: 0.8912\n",
            "Epoch 180/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2489 - accuracy: 0.8893 - val_loss: 0.3367 - val_accuracy: 0.8776\n",
            "Epoch 181/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2884 - accuracy: 0.8730 - val_loss: 0.3119 - val_accuracy: 0.8844\n",
            "Epoch 182/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2526 - accuracy: 0.8978 - val_loss: 0.3010 - val_accuracy: 0.8844\n",
            "Epoch 183/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2664 - accuracy: 0.8907 - val_loss: 0.2924 - val_accuracy: 0.8878\n",
            "Epoch 184/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.2805 - accuracy: 0.8798 - val_loss: 0.3071 - val_accuracy: 0.8878\n",
            "Epoch 185/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3007 - accuracy: 0.8454 - val_loss: 0.3213 - val_accuracy: 0.8776\n",
            "Epoch 186/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3108 - accuracy: 0.8553 - val_loss: 0.3841 - val_accuracy: 0.8639\n",
            "Epoch 187/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2991 - accuracy: 0.8667 - val_loss: 0.2923 - val_accuracy: 0.8810\n",
            "Epoch 188/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2736 - accuracy: 0.8824 - val_loss: 0.3025 - val_accuracy: 0.8878\n",
            "Epoch 189/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3077 - accuracy: 0.8638 - val_loss: 0.3285 - val_accuracy: 0.8571\n",
            "Epoch 190/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2771 - accuracy: 0.8838 - val_loss: 0.3053 - val_accuracy: 0.8741\n",
            "Epoch 191/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2690 - accuracy: 0.8825 - val_loss: 0.2860 - val_accuracy: 0.8810\n",
            "Epoch 192/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2543 - accuracy: 0.8882 - val_loss: 0.2829 - val_accuracy: 0.8776\n",
            "Epoch 193/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.2886 - accuracy: 0.8735 - val_loss: 0.2926 - val_accuracy: 0.8946\n",
            "Epoch 194/250\n",
            "32/32 [==============================] - 3s 100ms/step - loss: 0.2828 - accuracy: 0.8757 - val_loss: 0.2761 - val_accuracy: 0.8776\n",
            "Epoch 195/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2813 - accuracy: 0.8741 - val_loss: 0.3152 - val_accuracy: 0.8946\n",
            "Epoch 196/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2645 - accuracy: 0.8835 - val_loss: 0.2865 - val_accuracy: 0.8946\n",
            "Epoch 197/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2793 - accuracy: 0.8609 - val_loss: 0.3496 - val_accuracy: 0.8605\n",
            "Epoch 198/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2465 - accuracy: 0.8812 - val_loss: 0.2521 - val_accuracy: 0.8912\n",
            "Epoch 199/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3043 - accuracy: 0.8697 - val_loss: 0.2676 - val_accuracy: 0.9082\n",
            "Epoch 200/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2656 - accuracy: 0.8793 - val_loss: 0.3291 - val_accuracy: 0.8571\n",
            "Epoch 201/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2968 - accuracy: 0.8538 - val_loss: 0.3493 - val_accuracy: 0.8605\n",
            "Epoch 202/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2825 - accuracy: 0.8817 - val_loss: 0.2467 - val_accuracy: 0.9048\n",
            "Epoch 203/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2610 - accuracy: 0.8948 - val_loss: 0.2902 - val_accuracy: 0.8912\n",
            "Epoch 204/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2623 - accuracy: 0.8791 - val_loss: 0.2734 - val_accuracy: 0.9048\n",
            "Epoch 205/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2481 - accuracy: 0.8995 - val_loss: 0.2911 - val_accuracy: 0.8844\n",
            "Epoch 206/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2595 - accuracy: 0.8718 - val_loss: 0.2761 - val_accuracy: 0.8980\n",
            "Epoch 207/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2458 - accuracy: 0.8894 - val_loss: 0.3200 - val_accuracy: 0.8810\n",
            "Epoch 208/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2713 - accuracy: 0.8829 - val_loss: 0.2869 - val_accuracy: 0.8810\n",
            "Epoch 209/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2446 - accuracy: 0.8933 - val_loss: 0.2689 - val_accuracy: 0.8980\n",
            "Epoch 210/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2694 - accuracy: 0.8795 - val_loss: 0.2620 - val_accuracy: 0.9014\n",
            "Epoch 211/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2417 - accuracy: 0.8943 - val_loss: 0.3047 - val_accuracy: 0.8912\n",
            "Epoch 212/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2501 - accuracy: 0.8743 - val_loss: 0.2766 - val_accuracy: 0.8946\n",
            "Epoch 213/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.2964 - accuracy: 0.8613 - val_loss: 0.2663 - val_accuracy: 0.9082\n",
            "Epoch 214/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2428 - accuracy: 0.8905 - val_loss: 0.2851 - val_accuracy: 0.8844\n",
            "Epoch 215/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2488 - accuracy: 0.8900 - val_loss: 0.2786 - val_accuracy: 0.8912\n",
            "Epoch 216/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2814 - accuracy: 0.8861 - val_loss: 0.2855 - val_accuracy: 0.8912\n",
            "Epoch 217/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.2855 - accuracy: 0.8677 - val_loss: 0.2872 - val_accuracy: 0.8946\n",
            "Epoch 218/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2414 - accuracy: 0.9023 - val_loss: 0.2856 - val_accuracy: 0.8844\n",
            "Epoch 219/250\n",
            "32/32 [==============================] - 3s 105ms/step - loss: 0.2649 - accuracy: 0.8789 - val_loss: 0.2828 - val_accuracy: 0.8844\n",
            "Epoch 220/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3825 - accuracy: 0.8237 - val_loss: 0.2796 - val_accuracy: 0.8878\n",
            "Epoch 221/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2942 - accuracy: 0.8587 - val_loss: 0.2502 - val_accuracy: 0.9014\n",
            "Epoch 222/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2559 - accuracy: 0.8870 - val_loss: 0.2607 - val_accuracy: 0.8946\n",
            "Epoch 223/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2902 - accuracy: 0.8881 - val_loss: 0.2659 - val_accuracy: 0.8912\n",
            "Epoch 224/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2910 - accuracy: 0.8560 - val_loss: 0.2459 - val_accuracy: 0.8980\n",
            "Epoch 225/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2249 - accuracy: 0.9058 - val_loss: 0.2693 - val_accuracy: 0.8844\n",
            "Epoch 226/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2745 - accuracy: 0.8790 - val_loss: 0.3297 - val_accuracy: 0.8639\n",
            "Epoch 227/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2731 - accuracy: 0.8794 - val_loss: 0.2938 - val_accuracy: 0.8776\n",
            "Epoch 228/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2543 - accuracy: 0.8796 - val_loss: 0.2680 - val_accuracy: 0.8878\n",
            "Epoch 229/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2586 - accuracy: 0.8649 - val_loss: 0.3036 - val_accuracy: 0.8844\n",
            "Epoch 230/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2447 - accuracy: 0.9042 - val_loss: 0.2864 - val_accuracy: 0.8776\n",
            "Epoch 231/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2579 - accuracy: 0.8902 - val_loss: 0.2774 - val_accuracy: 0.9048\n",
            "Epoch 232/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2385 - accuracy: 0.8910 - val_loss: 0.4259 - val_accuracy: 0.8095\n",
            "Epoch 233/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2787 - accuracy: 0.8681 - val_loss: 0.3060 - val_accuracy: 0.8707\n",
            "Epoch 234/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2796 - accuracy: 0.8650 - val_loss: 0.2871 - val_accuracy: 0.8878\n",
            "Epoch 235/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2578 - accuracy: 0.8931 - val_loss: 0.3188 - val_accuracy: 0.8639\n",
            "Epoch 236/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2478 - accuracy: 0.8980 - val_loss: 0.2974 - val_accuracy: 0.8878\n",
            "Epoch 237/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2397 - accuracy: 0.8940 - val_loss: 0.3108 - val_accuracy: 0.8912\n",
            "Epoch 238/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2510 - accuracy: 0.9025 - val_loss: 0.3118 - val_accuracy: 0.8776\n",
            "Epoch 239/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2662 - accuracy: 0.8925 - val_loss: 0.2735 - val_accuracy: 0.8844\n",
            "Epoch 240/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2758 - accuracy: 0.8740 - val_loss: 0.2909 - val_accuracy: 0.8912\n",
            "Epoch 241/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2834 - accuracy: 0.8746 - val_loss: 0.3010 - val_accuracy: 0.8980\n",
            "Epoch 242/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2365 - accuracy: 0.8899 - val_loss: 0.3053 - val_accuracy: 0.8810\n",
            "Epoch 243/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2301 - accuracy: 0.8993 - val_loss: 0.3037 - val_accuracy: 0.8946\n",
            "Epoch 244/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2300 - accuracy: 0.8969 - val_loss: 0.2896 - val_accuracy: 0.8878\n",
            "Epoch 245/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2624 - accuracy: 0.8825 - val_loss: 0.2914 - val_accuracy: 0.8980\n",
            "Epoch 246/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2422 - accuracy: 0.8961 - val_loss: 0.2660 - val_accuracy: 0.9048\n",
            "Epoch 247/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2927 - accuracy: 0.8751 - val_loss: 0.3049 - val_accuracy: 0.8878\n",
            "Epoch 248/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2246 - accuracy: 0.8954 - val_loss: 0.2880 - val_accuracy: 0.8844\n",
            "Epoch 249/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2292 - accuracy: 0.8999 - val_loss: 0.2635 - val_accuracy: 0.8946\n",
            "Epoch 250/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2437 - accuracy: 0.9130 - val_loss: 0.3407 - val_accuracy: 0.8503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "32rKbdtmOT15",
        "outputId": "6f172471-50de-4dc2-ec0f-f46be32256aa"
      },
      "source": [
        "def plot_graphs(history, string):\r\n",
        "  plt.plot(history.history[string])\r\n",
        "  plt.plot(history.history['val_'+string])\r\n",
        "  plt.xlabel(\"Epochs\")\r\n",
        "  plt.ylabel(string)\r\n",
        "  plt.legend([string, 'val_'+string])\r\n",
        "  plt.ylim([0,1])\r\n",
        "  plt.grid()\r\n",
        "  plt.show()\r\n",
        "  \r\n",
        "plot_graphs(history, \"accuracy\")\r\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bQcLoc0j20Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e942f5-c7c2-49fe-f4f4-d0a9de6c2e25"
      },
      "source": [
        "results = model.evaluate([x_test, x_angle_test], y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3084 - accuracy: 0.8851\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}