{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9FI1e/YSyLXrILHm5Vf3H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eikeschuett/IcebergShipDetection/blob/DNN_Trial_and_Error/CNN_plus_Incl_Angle_0.9_Acc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp_u7zwvt_jw"
      },
      "source": [
        "import numpy as np # linear algebra\r\n",
        "np.random.seed(666)\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from subprocess import check_output\r\n",
        "from matplotlib import pyplot\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\r\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.layers.merge import Concatenate\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.optimizers import Adam, SGD\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from scipy.ndimage.filters import uniform_filter\r\n",
        "from scipy.ndimage.measurements import variance"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "7nYBzmT4uDBU",
        "outputId": "eb1f09b2-4fe2-4f16-bd0f-a9319e15fb7e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive')\r\n",
        "data = pd.read_json('/content/drive/MyDrive/Iceberg_Ship_Classification/train.json')\r\n",
        "\r\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>band_1</th>\n",
              "      <th>band_2</th>\n",
              "      <th>inc_angle</th>\n",
              "      <th>is_iceberg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dfd5f913</td>\n",
              "      <td>[-27.878360999999998, -27.15416, -28.668615, -...</td>\n",
              "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
              "      <td>43.9239</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e25388fd</td>\n",
              "      <td>[-12.242375, -14.920304999999999, -14.920363, ...</td>\n",
              "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
              "      <td>38.1562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>58b2aaa0</td>\n",
              "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
              "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
              "      <td>45.2859</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4cfc3a18</td>\n",
              "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
              "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
              "      <td>43.8306</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>271f93f4</td>\n",
              "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
              "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
              "      <td>35.6256</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... is_iceberg\n",
              "0  dfd5f913  ...          0\n",
              "1  e25388fd  ...          0\n",
              "2  58b2aaa0  ...          1\n",
              "3  4cfc3a18  ...          0\n",
              "4  271f93f4  ...          0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LbOp4V82ZMg"
      },
      "source": [
        "Delete all observations without an inclination angle (133 in total) instead of replacing it with some random values... Then rescale the inclination angle between -1 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiyDkJP5gPwu",
        "outputId": "f6233c0d-5741-4fe2-e892-cab97bfe8db8"
      },
      "source": [
        "print(len(data))\r\n",
        "data.inc_angle = data.inc_angle.replace('na', np.nan)\r\n",
        "\r\n",
        "#data.inc_angle = data.inc_angle.astype(float).fillna(0.0)\r\n",
        "data = data.dropna(axis=0, how='any')\r\n",
        "print(len(data))\r\n",
        "print(data.inc_angle.min())\r\n",
        "print(data.inc_angle.max())\r\n",
        "data.inc_angle = 2*(data.inc_angle - 20)/(50-20)-1\r\n",
        "print(data.inc_angle.min())\r\n",
        "print(data.inc_angle.max())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1604\n",
            "1471\n",
            "24.7546\n",
            "45.9375\n",
            "-0.6830266666666667\n",
            "0.7291666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzAKZG0RuZ2b"
      },
      "source": [
        "def lee_filter(img, size):\r\n",
        "    # From here: https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\r\n",
        "    img_mean = uniform_filter(img, (size, size))\r\n",
        "    img_sqr_mean = uniform_filter(img**2, (size, size))\r\n",
        "    img_variance = img_sqr_mean - img_mean**2\r\n",
        "\r\n",
        "    overall_variance = variance(img)\r\n",
        "\r\n",
        "    img_weights = img_variance / (img_variance + overall_variance)\r\n",
        "    img_output = img_mean + img_weights * (img - img_mean)\r\n",
        "    return img_output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqww4ARyuabj"
      },
      "source": [
        "def prepare_data(data):\r\n",
        "  x_angle = np.array(data[\"inc_angle\"])\r\n",
        "\r\n",
        "  # Get the labels (y-values)\r\n",
        "  labels = np.array(data[\"is_iceberg\"])\r\n",
        "\r\n",
        "  # Create empty list for the images\r\n",
        "  imgs = []\r\n",
        "  for i, row in data.iterrows():\r\n",
        "      # Reshape list to image\r\n",
        "      hh  = np.reshape(row[\"band_1\"], (75, 75))\r\n",
        "      hv  = np.reshape(row[\"band_2\"], (75, 75))\r\n",
        "      b3  = hh + hv\r\n",
        "\r\n",
        "      hh = lee_filter(hh, 20)\r\n",
        "      hv = lee_filter(hv, 20)\r\n",
        "      b3 = lee_filter(b3, 20)      \r\n",
        "        \r\n",
        "      # Rescale images between 0 and 1 for faster convergence rate\r\n",
        "      hh = (hh - hh.min())/(hh.max()-hh.min())\r\n",
        "      hv = (hv - hv.min())/(hv.max()-hv.min())\r\n",
        "      b3 = (b3 - b3.min())/(b3.max()-b3.min())      \r\n",
        "\r\n",
        "      # Stack the bands and append them to imgs\r\n",
        "      imgs.append(np.dstack((hh, hv, b3)))\r\n",
        "      \r\n",
        "  # Split dataset into training (70%)  and validation (30 %)\r\n",
        "  x_train, x_val, x_angle_train, x_angle_val, y_train, y_val = train_test_split(imgs, \r\n",
        "                                                    x_angle,\r\n",
        "                                                    labels, \r\n",
        "                                                    test_size=0.3, \r\n",
        "                                                    random_state=0)\r\n",
        "  # Then split validation dataset into validation (20 %) and testing (10 %)\r\n",
        "  x_val, x_test, x_angle_val, x_angle_test, y_val, y_test = train_test_split(x_val,\r\n",
        "                                                  x_angle_val,\r\n",
        "                                                  y_val,\r\n",
        "                                                  test_size=(1/3),\r\n",
        "                                                  random_state=0)\r\n",
        "\r\n",
        "  x_train = np.array(x_train)\r\n",
        "  x_test = np.array(x_test)\r\n",
        "  x_val = np.array(x_val)\r\n",
        "  x_angle_test = np.array(x_angle_test)\r\n",
        "  x_angle_train = np.array(x_angle_train)\r\n",
        "  x_angle_val = np.array(x_angle_val)\r\n",
        "  return x_train, x_val, x_test, x_angle_train, x_angle_val, x_angle_test, y_train, y_val, y_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28CxgXc60t2u",
        "outputId": "23141592-c1cd-46f7-8124-08a24d780518"
      },
      "source": [
        "x_train, x_val, x_test, x_angle_train, x_angle_val, x_angle_test, y_train, y_val, y_test = prepare_data(data)\r\n",
        "print(\"Number of samples for training: \" + str(len(x_train)) + \" (\" + str(round(len(x_train)/len(data), 4)*100) + \" %)\")\r\n",
        "print(\"Number of samples for validation: \" + str(len(x_val)) + \" (\" + str(round(len(x_val)/len(data), 4)*100) + \" %)\")\r\n",
        "print(\"Number of samples for testing: \" + str(len(x_test)) + \" (\" + str(round(len(x_test)/len(data), 4)*100) + \" %)\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples for training: 1029 (69.95 %)\n",
            "Number of samples for validation: 294 (19.99 %)\n",
            "Number of samples for testing: 148 (10.059999999999999 %)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oezdQAC3Zx_"
      },
      "source": [
        "Create two data generators for both images and the inclination angle and combine them. I have the code from https://www.kaggle.com/sinkie/keras-data-augmentation-with-multiple-inputs, but still don't understand what this is doing exactly..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-_w43W5M60A"
      },
      "source": [
        "# From here: https://www.kaggle.com/sinkie/keras-data-augmentation-with-multiple-inputs\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "gen = ImageDataGenerator(\r\n",
        "      rotation_range = 45,\r\n",
        "      width_shift_range = 0.15,\r\n",
        "      height_shift_range = 0.15,\r\n",
        "      shear_range = 0.15,\r\n",
        "      zoom_range = 0.15,\r\n",
        "      horizontal_flip = True,\r\n",
        "      vertical_flip = True,\r\n",
        "      fill_mode = 'nearest')\r\n",
        "\r\n",
        "# Here is the function that merges our two generators\r\n",
        "# We use the exact same generator with the same random seed for both the y and angle arrays\r\n",
        "def gen_flow_for_two_inputs(X1, X2, y):\r\n",
        "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=666)\r\n",
        "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=666)\r\n",
        "    while True:\r\n",
        "            X1i = genX1.next()\r\n",
        "            X2i = genX2.next()\r\n",
        "            #Assert arrays are equal - this was for peace of mind, but slows down training\r\n",
        "            #np.testing.assert_array_equal(X1i[0],X2i[0])\r\n",
        "            yield [X1i[0], X2i[1]], X1i[1]\r\n",
        "\r\n",
        "# Finally create generator\r\n",
        "gen_flow = gen_flow_for_two_inputs(x_train, x_angle_train, y_train)\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b32oC96X1c1M"
      },
      "source": [
        "# train_generator, val_generator = DataGenerators(x_train, x_val, y_train, y_val)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVC3fO7Hw5Uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3a39c3-37dc-4f29-bb0e-6de4f1046ee8"
      },
      "source": [
        "def create_model(optimizer):\r\n",
        "  ac_fct      = \"relu\"\r\n",
        "  #momentum    = 0\r\n",
        "\r\n",
        "  input_img   = Input(shape=(75, 75 ,3), name=\"X_img\")\r\n",
        "  input_angle = Input(shape=[1], name=\"angle\")\r\n",
        "\r\n",
        "  #cnn = BatchNormalization()(input_img)\r\n",
        "  cnn = Conv2D(16, kernel_size=(3,3), activation = \"relu\")(input_img)\r\n",
        "  #cnn = Conv2D(16, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  cnn = MaxPooling2D((2,2))(cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)\r\n",
        "\r\n",
        "  cnn = Conv2D(32, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  #cnn = Conv2D(32, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  cnn = MaxPooling2D((2,2)) (cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)\r\n",
        "\r\n",
        "  cnn = Conv2D(64, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  #cnn = Conv2D(64, kernel_size=(3,3), activation = \"relu\") (cnn)\r\n",
        "  cnn = MaxPooling2D((2,2)) (cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)  \r\n",
        "\r\n",
        "  cnn = Conv2D(128, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  cnn = Conv2D(128, kernel_size=(3,3), activation = \"relu\") (cnn)\r\n",
        "  cnn = MaxPooling2D((2,2)) (cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)  \r\n",
        "  \r\n",
        "\r\n",
        "  cnn = GlobalMaxPooling2D() (cnn)\r\n",
        "\r\n",
        "  #angle = BatchNormalization(momentum=0)(input_angle)\r\n",
        "\r\n",
        "  concat = (Concatenate()([cnn, input_angle]))\r\n",
        "\r\n",
        "  dense = Dense(32, activation=\"relu\") (concat)\r\n",
        "  # dense = BatchNormalization() (dense)\r\n",
        "  # dense = Dropout(0.2)(dense)\r\n",
        "  \r\n",
        "  #dense = Dense(128, activation=\"relu\") (dense)\r\n",
        "  #dense = BatchNormalization() (dense)\r\n",
        "  #dense = Dropout(0.2)(dense)\r\n",
        "\r\n",
        "  #dense = Dense(128, activation=\"relu\") (dense)\r\n",
        "  #dense = BatchNormalization() (dense)\r\n",
        "  #dense = Dropout(0.2)(dense)\r\n",
        "\r\n",
        "  output = Dense(1, activation=\"sigmoid\")(dense)\r\n",
        "\r\n",
        "  model = Model([input_img, input_angle], output)\r\n",
        "  #optimizer = Adam(lr=0.1, epsilon=1e-08, decay=0.0)\r\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\r\n",
        "  return model\r\n",
        "\r\n",
        "epochs = 250\r\n",
        "# learning_rate = 0.1\r\n",
        "# decay_rate = learning_rate / epochs\r\n",
        "# momentum = 0.8\r\n",
        "# sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\r\n",
        "\r\n",
        "# from keras.optimizers import Adadelta\r\n",
        "model = create_model(optimizer = Adam())\r\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "X_img (InputLayer)              [(None, 75, 75, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 73, 73, 16)   448         X_img[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 36, 36, 16)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 36, 36, 16)   0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 34, 34, 32)   4640        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 17, 17, 32)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 17, 17, 32)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 15, 15, 64)   18496       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 64)     0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 64)     0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 5, 5, 128)    73856       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 3, 3, 128)    147584      conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1, 1, 128)    0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 128)          0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "angle (InputLayer)              [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 129)          0           global_max_pooling2d[0][0]       \n",
            "                                                                 angle[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           4160        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 249,217\n",
            "Trainable params: 249,217\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpDHGNPh1KSV"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJbwtdGeNO02",
        "outputId": "b9cecd9a-3335-4c93-c9b4-954621d18a71"
      },
      "source": [
        "history = model.fit(gen_flow, validation_data=([x_val, x_angle_val], y_val),\r\n",
        "                    steps_per_epoch=len(x_train) / batch_size, epochs=epochs)\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "32/32 [==============================] - 6s 110ms/step - loss: 0.6940 - accuracy: 0.5209 - val_loss: 0.6726 - val_accuracy: 0.6735\n",
            "Epoch 2/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.6600 - accuracy: 0.5847 - val_loss: 0.6017 - val_accuracy: 0.6803\n",
            "Epoch 3/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.6257 - accuracy: 0.6626 - val_loss: 0.5637 - val_accuracy: 0.6803\n",
            "Epoch 4/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.5772 - accuracy: 0.6891 - val_loss: 0.5354 - val_accuracy: 0.7075\n",
            "Epoch 5/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.5601 - accuracy: 0.7211 - val_loss: 0.4983 - val_accuracy: 0.7653\n",
            "Epoch 6/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.5634 - accuracy: 0.7122 - val_loss: 0.5306 - val_accuracy: 0.7313\n",
            "Epoch 7/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.5954 - accuracy: 0.6756 - val_loss: 0.5103 - val_accuracy: 0.7517\n",
            "Epoch 8/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.5330 - accuracy: 0.7489 - val_loss: 0.5564 - val_accuracy: 0.7449\n",
            "Epoch 9/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.5194 - accuracy: 0.7487 - val_loss: 0.4812 - val_accuracy: 0.7619\n",
            "Epoch 10/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.4902 - accuracy: 0.7819 - val_loss: 0.4415 - val_accuracy: 0.8027\n",
            "Epoch 11/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.4631 - accuracy: 0.7885 - val_loss: 0.5272 - val_accuracy: 0.7313\n",
            "Epoch 12/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.5603 - accuracy: 0.7005 - val_loss: 0.4346 - val_accuracy: 0.7959\n",
            "Epoch 13/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.4816 - accuracy: 0.7612 - val_loss: 0.3929 - val_accuracy: 0.8299\n",
            "Epoch 14/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.4216 - accuracy: 0.7979 - val_loss: 0.3702 - val_accuracy: 0.8401\n",
            "Epoch 15/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.4355 - accuracy: 0.7984 - val_loss: 0.4143 - val_accuracy: 0.8197\n",
            "Epoch 16/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.4600 - accuracy: 0.7723 - val_loss: 0.3646 - val_accuracy: 0.8469\n",
            "Epoch 17/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.4029 - accuracy: 0.8313 - val_loss: 0.3667 - val_accuracy: 0.8401\n",
            "Epoch 18/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3921 - accuracy: 0.8069 - val_loss: 0.3559 - val_accuracy: 0.8435\n",
            "Epoch 19/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.4710 - accuracy: 0.7819 - val_loss: 0.4126 - val_accuracy: 0.8265\n",
            "Epoch 20/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3913 - accuracy: 0.8163 - val_loss: 0.3588 - val_accuracy: 0.8503\n",
            "Epoch 21/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.4430 - accuracy: 0.7876 - val_loss: 0.3778 - val_accuracy: 0.8367\n",
            "Epoch 22/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3969 - accuracy: 0.8058 - val_loss: 0.3766 - val_accuracy: 0.8537\n",
            "Epoch 23/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3945 - accuracy: 0.8305 - val_loss: 0.3353 - val_accuracy: 0.8605\n",
            "Epoch 24/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3934 - accuracy: 0.7952 - val_loss: 0.3883 - val_accuracy: 0.8333\n",
            "Epoch 25/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3848 - accuracy: 0.8117 - val_loss: 0.3384 - val_accuracy: 0.8605\n",
            "Epoch 26/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.3689 - accuracy: 0.8382 - val_loss: 0.3731 - val_accuracy: 0.8231\n",
            "Epoch 27/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.4301 - accuracy: 0.7814 - val_loss: 0.3108 - val_accuracy: 0.8707\n",
            "Epoch 28/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3729 - accuracy: 0.8161 - val_loss: 0.3698 - val_accuracy: 0.8435\n",
            "Epoch 29/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.3652 - accuracy: 0.8323 - val_loss: 0.3273 - val_accuracy: 0.8639\n",
            "Epoch 30/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3750 - accuracy: 0.8113 - val_loss: 0.3714 - val_accuracy: 0.8571\n",
            "Epoch 31/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3679 - accuracy: 0.8184 - val_loss: 0.3138 - val_accuracy: 0.8707\n",
            "Epoch 32/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3758 - accuracy: 0.8206 - val_loss: 0.3334 - val_accuracy: 0.8639\n",
            "Epoch 33/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.3877 - accuracy: 0.8315 - val_loss: 0.3509 - val_accuracy: 0.8469\n",
            "Epoch 34/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.3574 - accuracy: 0.8227 - val_loss: 0.3080 - val_accuracy: 0.8639\n",
            "Epoch 35/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.3384 - accuracy: 0.8512 - val_loss: 0.3938 - val_accuracy: 0.8265\n",
            "Epoch 36/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3974 - accuracy: 0.8121 - val_loss: 0.4295 - val_accuracy: 0.8027\n",
            "Epoch 37/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.3890 - accuracy: 0.8026 - val_loss: 0.3774 - val_accuracy: 0.8401\n",
            "Epoch 38/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.4081 - accuracy: 0.7916 - val_loss: 0.3418 - val_accuracy: 0.8571\n",
            "Epoch 39/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3583 - accuracy: 0.8321 - val_loss: 0.3179 - val_accuracy: 0.8571\n",
            "Epoch 40/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3937 - accuracy: 0.8131 - val_loss: 0.3242 - val_accuracy: 0.8673\n",
            "Epoch 41/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3995 - accuracy: 0.8058 - val_loss: 0.3205 - val_accuracy: 0.8673\n",
            "Epoch 42/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3314 - accuracy: 0.8448 - val_loss: 0.3199 - val_accuracy: 0.8673\n",
            "Epoch 43/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3836 - accuracy: 0.8101 - val_loss: 0.3276 - val_accuracy: 0.8571\n",
            "Epoch 44/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3603 - accuracy: 0.8352 - val_loss: 0.3217 - val_accuracy: 0.8605\n",
            "Epoch 45/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3424 - accuracy: 0.8528 - val_loss: 0.3167 - val_accuracy: 0.8707\n",
            "Epoch 46/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3430 - accuracy: 0.8200 - val_loss: 0.3241 - val_accuracy: 0.8673\n",
            "Epoch 47/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3677 - accuracy: 0.8261 - val_loss: 0.3112 - val_accuracy: 0.8741\n",
            "Epoch 48/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3506 - accuracy: 0.8343 - val_loss: 0.3330 - val_accuracy: 0.8639\n",
            "Epoch 49/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3673 - accuracy: 0.8326 - val_loss: 0.3348 - val_accuracy: 0.8571\n",
            "Epoch 50/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3611 - accuracy: 0.8254 - val_loss: 0.3138 - val_accuracy: 0.8707\n",
            "Epoch 51/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3928 - accuracy: 0.8206 - val_loss: 0.3014 - val_accuracy: 0.8844\n",
            "Epoch 52/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3485 - accuracy: 0.8376 - val_loss: 0.2978 - val_accuracy: 0.8776\n",
            "Epoch 53/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3357 - accuracy: 0.8403 - val_loss: 0.3341 - val_accuracy: 0.8741\n",
            "Epoch 54/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3894 - accuracy: 0.8321 - val_loss: 0.2916 - val_accuracy: 0.8844\n",
            "Epoch 55/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3320 - accuracy: 0.8413 - val_loss: 0.3097 - val_accuracy: 0.8673\n",
            "Epoch 56/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3395 - accuracy: 0.8535 - val_loss: 0.3189 - val_accuracy: 0.8741\n",
            "Epoch 57/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3750 - accuracy: 0.8224 - val_loss: 0.3461 - val_accuracy: 0.8605\n",
            "Epoch 58/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.3612 - accuracy: 0.8395 - val_loss: 0.3168 - val_accuracy: 0.8639\n",
            "Epoch 59/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3411 - accuracy: 0.8432 - val_loss: 0.3339 - val_accuracy: 0.8469\n",
            "Epoch 60/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3806 - accuracy: 0.8254 - val_loss: 0.3071 - val_accuracy: 0.8810\n",
            "Epoch 61/250\n",
            "32/32 [==============================] - 3s 86ms/step - loss: 0.3684 - accuracy: 0.8389 - val_loss: 0.2982 - val_accuracy: 0.8844\n",
            "Epoch 62/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3310 - accuracy: 0.8535 - val_loss: 0.3093 - val_accuracy: 0.8707\n",
            "Epoch 63/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3147 - accuracy: 0.8546 - val_loss: 0.3162 - val_accuracy: 0.8673\n",
            "Epoch 64/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3818 - accuracy: 0.8253 - val_loss: 0.3303 - val_accuracy: 0.8605\n",
            "Epoch 65/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3415 - accuracy: 0.8379 - val_loss: 0.3037 - val_accuracy: 0.8776\n",
            "Epoch 66/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3420 - accuracy: 0.8464 - val_loss: 0.3137 - val_accuracy: 0.8571\n",
            "Epoch 67/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3251 - accuracy: 0.8423 - val_loss: 0.3492 - val_accuracy: 0.8401\n",
            "Epoch 68/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3501 - accuracy: 0.8217 - val_loss: 0.3058 - val_accuracy: 0.8673\n",
            "Epoch 69/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3862 - accuracy: 0.8222 - val_loss: 0.3206 - val_accuracy: 0.8741\n",
            "Epoch 70/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3282 - accuracy: 0.8397 - val_loss: 0.3038 - val_accuracy: 0.8639\n",
            "Epoch 71/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3618 - accuracy: 0.8421 - val_loss: 0.2910 - val_accuracy: 0.8673\n",
            "Epoch 72/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3543 - accuracy: 0.8528 - val_loss: 0.3228 - val_accuracy: 0.8844\n",
            "Epoch 73/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3696 - accuracy: 0.8286 - val_loss: 0.3341 - val_accuracy: 0.8639\n",
            "Epoch 74/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3247 - accuracy: 0.8517 - val_loss: 0.2974 - val_accuracy: 0.8912\n",
            "Epoch 75/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3449 - accuracy: 0.8500 - val_loss: 0.3056 - val_accuracy: 0.8776\n",
            "Epoch 76/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3142 - accuracy: 0.8589 - val_loss: 0.3278 - val_accuracy: 0.8639\n",
            "Epoch 77/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3530 - accuracy: 0.8368 - val_loss: 0.3278 - val_accuracy: 0.8537\n",
            "Epoch 78/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3316 - accuracy: 0.8359 - val_loss: 0.2924 - val_accuracy: 0.8844\n",
            "Epoch 79/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.2998 - accuracy: 0.8785 - val_loss: 0.3331 - val_accuracy: 0.8810\n",
            "Epoch 80/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3672 - accuracy: 0.8242 - val_loss: 0.3036 - val_accuracy: 0.8844\n",
            "Epoch 81/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3158 - accuracy: 0.8543 - val_loss: 0.2978 - val_accuracy: 0.8810\n",
            "Epoch 82/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3463 - accuracy: 0.8276 - val_loss: 0.2876 - val_accuracy: 0.8810\n",
            "Epoch 83/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3584 - accuracy: 0.8217 - val_loss: 0.3007 - val_accuracy: 0.8776\n",
            "Epoch 84/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3179 - accuracy: 0.8492 - val_loss: 0.3093 - val_accuracy: 0.8912\n",
            "Epoch 85/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3193 - accuracy: 0.8681 - val_loss: 0.3202 - val_accuracy: 0.8639\n",
            "Epoch 86/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3155 - accuracy: 0.8631 - val_loss: 0.2941 - val_accuracy: 0.8707\n",
            "Epoch 87/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3434 - accuracy: 0.8477 - val_loss: 0.2862 - val_accuracy: 0.8776\n",
            "Epoch 88/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3522 - accuracy: 0.8313 - val_loss: 0.3040 - val_accuracy: 0.8776\n",
            "Epoch 89/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.2946 - accuracy: 0.8759 - val_loss: 0.2929 - val_accuracy: 0.8810\n",
            "Epoch 90/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3257 - accuracy: 0.8490 - val_loss: 0.3104 - val_accuracy: 0.8673\n",
            "Epoch 91/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3101 - accuracy: 0.8435 - val_loss: 0.3033 - val_accuracy: 0.8639\n",
            "Epoch 92/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3015 - accuracy: 0.8615 - val_loss: 0.3004 - val_accuracy: 0.8776\n",
            "Epoch 93/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3108 - accuracy: 0.8531 - val_loss: 0.2995 - val_accuracy: 0.8912\n",
            "Epoch 94/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3079 - accuracy: 0.8636 - val_loss: 0.3018 - val_accuracy: 0.9048\n",
            "Epoch 95/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3009 - accuracy: 0.8705 - val_loss: 0.3265 - val_accuracy: 0.8878\n",
            "Epoch 96/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3193 - accuracy: 0.8305 - val_loss: 0.2787 - val_accuracy: 0.8741\n",
            "Epoch 97/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.2963 - accuracy: 0.8774 - val_loss: 0.3020 - val_accuracy: 0.8707\n",
            "Epoch 98/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3184 - accuracy: 0.8520 - val_loss: 0.3081 - val_accuracy: 0.8878\n",
            "Epoch 99/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2847 - accuracy: 0.8797 - val_loss: 0.3048 - val_accuracy: 0.8707\n",
            "Epoch 100/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3224 - accuracy: 0.8648 - val_loss: 0.3660 - val_accuracy: 0.8333\n",
            "Epoch 101/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3191 - accuracy: 0.8711 - val_loss: 0.2795 - val_accuracy: 0.8810\n",
            "Epoch 102/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3380 - accuracy: 0.8630 - val_loss: 0.3057 - val_accuracy: 0.8707\n",
            "Epoch 103/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3332 - accuracy: 0.8452 - val_loss: 0.2719 - val_accuracy: 0.8878\n",
            "Epoch 104/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3114 - accuracy: 0.8699 - val_loss: 0.3520 - val_accuracy: 0.8435\n",
            "Epoch 105/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3323 - accuracy: 0.8483 - val_loss: 0.2941 - val_accuracy: 0.8707\n",
            "Epoch 106/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3095 - accuracy: 0.8649 - val_loss: 0.2853 - val_accuracy: 0.8946\n",
            "Epoch 107/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3104 - accuracy: 0.8658 - val_loss: 0.3376 - val_accuracy: 0.8673\n",
            "Epoch 108/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3351 - accuracy: 0.8475 - val_loss: 0.2988 - val_accuracy: 0.8878\n",
            "Epoch 109/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3082 - accuracy: 0.8684 - val_loss: 0.3083 - val_accuracy: 0.8810\n",
            "Epoch 110/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3177 - accuracy: 0.8531 - val_loss: 0.2949 - val_accuracy: 0.8776\n",
            "Epoch 111/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2861 - accuracy: 0.8817 - val_loss: 0.2856 - val_accuracy: 0.8878\n",
            "Epoch 112/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3166 - accuracy: 0.8574 - val_loss: 0.3430 - val_accuracy: 0.8401\n",
            "Epoch 113/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3403 - accuracy: 0.8529 - val_loss: 0.3442 - val_accuracy: 0.8571\n",
            "Epoch 114/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3886 - accuracy: 0.8352 - val_loss: 0.2771 - val_accuracy: 0.8810\n",
            "Epoch 115/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.2893 - accuracy: 0.8685 - val_loss: 0.3450 - val_accuracy: 0.8571\n",
            "Epoch 116/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3268 - accuracy: 0.8516 - val_loss: 0.2690 - val_accuracy: 0.8946\n",
            "Epoch 117/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3392 - accuracy: 0.8575 - val_loss: 0.2828 - val_accuracy: 0.8878\n",
            "Epoch 118/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.2904 - accuracy: 0.8591 - val_loss: 0.3386 - val_accuracy: 0.8605\n",
            "Epoch 119/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3645 - accuracy: 0.8444 - val_loss: 0.3236 - val_accuracy: 0.8844\n",
            "Epoch 120/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3027 - accuracy: 0.8670 - val_loss: 0.2678 - val_accuracy: 0.8878\n",
            "Epoch 121/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2796 - accuracy: 0.8673 - val_loss: 0.2727 - val_accuracy: 0.8912\n",
            "Epoch 122/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3328 - accuracy: 0.8649 - val_loss: 0.3152 - val_accuracy: 0.8673\n",
            "Epoch 123/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2592 - accuracy: 0.8768 - val_loss: 0.3218 - val_accuracy: 0.8810\n",
            "Epoch 124/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3007 - accuracy: 0.8657 - val_loss: 0.2796 - val_accuracy: 0.8878\n",
            "Epoch 125/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.2985 - accuracy: 0.8906 - val_loss: 0.2925 - val_accuracy: 0.8946\n",
            "Epoch 126/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3035 - accuracy: 0.8432 - val_loss: 0.2860 - val_accuracy: 0.8878\n",
            "Epoch 127/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3009 - accuracy: 0.8640 - val_loss: 0.2977 - val_accuracy: 0.8810\n",
            "Epoch 128/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2770 - accuracy: 0.8794 - val_loss: 0.3228 - val_accuracy: 0.8673\n",
            "Epoch 129/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2855 - accuracy: 0.8662 - val_loss: 0.2819 - val_accuracy: 0.8878\n",
            "Epoch 130/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.2793 - accuracy: 0.8924 - val_loss: 0.3005 - val_accuracy: 0.8946\n",
            "Epoch 131/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2842 - accuracy: 0.8662 - val_loss: 0.3879 - val_accuracy: 0.8469\n",
            "Epoch 132/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3266 - accuracy: 0.8536 - val_loss: 0.2686 - val_accuracy: 0.9014\n",
            "Epoch 133/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2986 - accuracy: 0.8722 - val_loss: 0.2722 - val_accuracy: 0.8776\n",
            "Epoch 134/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3007 - accuracy: 0.8715 - val_loss: 0.2866 - val_accuracy: 0.8741\n",
            "Epoch 135/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2989 - accuracy: 0.8757 - val_loss: 0.2932 - val_accuracy: 0.8707\n",
            "Epoch 136/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3103 - accuracy: 0.8492 - val_loss: 0.3026 - val_accuracy: 0.8776\n",
            "Epoch 137/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3154 - accuracy: 0.8447 - val_loss: 0.2841 - val_accuracy: 0.8878\n",
            "Epoch 138/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2992 - accuracy: 0.8635 - val_loss: 0.3053 - val_accuracy: 0.8741\n",
            "Epoch 139/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.2818 - accuracy: 0.8827 - val_loss: 0.2944 - val_accuracy: 0.8776\n",
            "Epoch 140/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3106 - accuracy: 0.8556 - val_loss: 0.3141 - val_accuracy: 0.8776\n",
            "Epoch 141/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3344 - accuracy: 0.8539 - val_loss: 0.2620 - val_accuracy: 0.8878\n",
            "Epoch 142/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2685 - accuracy: 0.8794 - val_loss: 0.2929 - val_accuracy: 0.8810\n",
            "Epoch 143/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3090 - accuracy: 0.8617 - val_loss: 0.2946 - val_accuracy: 0.8810\n",
            "Epoch 144/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2716 - accuracy: 0.8743 - val_loss: 0.2952 - val_accuracy: 0.8810\n",
            "Epoch 145/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3457 - accuracy: 0.8309 - val_loss: 0.2885 - val_accuracy: 0.8776\n",
            "Epoch 146/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2987 - accuracy: 0.8708 - val_loss: 0.2923 - val_accuracy: 0.8639\n",
            "Epoch 147/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2990 - accuracy: 0.8683 - val_loss: 0.2581 - val_accuracy: 0.9014\n",
            "Epoch 148/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2857 - accuracy: 0.8743 - val_loss: 0.2848 - val_accuracy: 0.8776\n",
            "Epoch 149/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2715 - accuracy: 0.8776 - val_loss: 0.2775 - val_accuracy: 0.8878\n",
            "Epoch 150/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2665 - accuracy: 0.8917 - val_loss: 0.2995 - val_accuracy: 0.8741\n",
            "Epoch 151/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3209 - accuracy: 0.8576 - val_loss: 0.2830 - val_accuracy: 0.8980\n",
            "Epoch 152/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2970 - accuracy: 0.8775 - val_loss: 0.2973 - val_accuracy: 0.8707\n",
            "Epoch 153/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2996 - accuracy: 0.8700 - val_loss: 0.2779 - val_accuracy: 0.8673\n",
            "Epoch 154/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3075 - accuracy: 0.8613 - val_loss: 0.3257 - val_accuracy: 0.8776\n",
            "Epoch 155/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2748 - accuracy: 0.8766 - val_loss: 0.2998 - val_accuracy: 0.8741\n",
            "Epoch 156/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3008 - accuracy: 0.8590 - val_loss: 0.2913 - val_accuracy: 0.8673\n",
            "Epoch 157/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2762 - accuracy: 0.8682 - val_loss: 0.3088 - val_accuracy: 0.8776\n",
            "Epoch 158/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2943 - accuracy: 0.8781 - val_loss: 0.2870 - val_accuracy: 0.8946\n",
            "Epoch 159/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2781 - accuracy: 0.8835 - val_loss: 0.2766 - val_accuracy: 0.8912\n",
            "Epoch 160/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2877 - accuracy: 0.8717 - val_loss: 0.2770 - val_accuracy: 0.8912\n",
            "Epoch 161/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2941 - accuracy: 0.8609 - val_loss: 0.2955 - val_accuracy: 0.8776\n",
            "Epoch 162/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2736 - accuracy: 0.8669 - val_loss: 0.3074 - val_accuracy: 0.8673\n",
            "Epoch 163/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2807 - accuracy: 0.8782 - val_loss: 0.3137 - val_accuracy: 0.8741\n",
            "Epoch 164/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2923 - accuracy: 0.8617 - val_loss: 0.2968 - val_accuracy: 0.8707\n",
            "Epoch 165/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2992 - accuracy: 0.8629 - val_loss: 0.2920 - val_accuracy: 0.8844\n",
            "Epoch 166/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2659 - accuracy: 0.8832 - val_loss: 0.2839 - val_accuracy: 0.8776\n",
            "Epoch 167/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2727 - accuracy: 0.9011 - val_loss: 0.3328 - val_accuracy: 0.8435\n",
            "Epoch 168/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3153 - accuracy: 0.8718 - val_loss: 0.2838 - val_accuracy: 0.9014\n",
            "Epoch 169/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2931 - accuracy: 0.8873 - val_loss: 0.2812 - val_accuracy: 0.8673\n",
            "Epoch 170/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2688 - accuracy: 0.8757 - val_loss: 0.2847 - val_accuracy: 0.8810\n",
            "Epoch 171/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2847 - accuracy: 0.8818 - val_loss: 0.2995 - val_accuracy: 0.8707\n",
            "Epoch 172/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2802 - accuracy: 0.8831 - val_loss: 0.2937 - val_accuracy: 0.8912\n",
            "Epoch 173/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2705 - accuracy: 0.8657 - val_loss: 0.3506 - val_accuracy: 0.8435\n",
            "Epoch 174/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3183 - accuracy: 0.8635 - val_loss: 0.2937 - val_accuracy: 0.8639\n",
            "Epoch 175/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2668 - accuracy: 0.8779 - val_loss: 0.3457 - val_accuracy: 0.8537\n",
            "Epoch 176/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3180 - accuracy: 0.8623 - val_loss: 0.2931 - val_accuracy: 0.8707\n",
            "Epoch 177/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3136 - accuracy: 0.8622 - val_loss: 0.2827 - val_accuracy: 0.9014\n",
            "Epoch 178/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2764 - accuracy: 0.8799 - val_loss: 0.3130 - val_accuracy: 0.8605\n",
            "Epoch 179/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3037 - accuracy: 0.8707 - val_loss: 0.3244 - val_accuracy: 0.8741\n",
            "Epoch 180/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2955 - accuracy: 0.8686 - val_loss: 0.2996 - val_accuracy: 0.8844\n",
            "Epoch 181/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2793 - accuracy: 0.8671 - val_loss: 0.3067 - val_accuracy: 0.8810\n",
            "Epoch 182/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2758 - accuracy: 0.8795 - val_loss: 0.2881 - val_accuracy: 0.9014\n",
            "Epoch 183/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3003 - accuracy: 0.8684 - val_loss: 0.2984 - val_accuracy: 0.8707\n",
            "Epoch 184/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2540 - accuracy: 0.8936 - val_loss: 0.3021 - val_accuracy: 0.8878\n",
            "Epoch 185/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2778 - accuracy: 0.8665 - val_loss: 0.3962 - val_accuracy: 0.8639\n",
            "Epoch 186/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3131 - accuracy: 0.8547 - val_loss: 0.3461 - val_accuracy: 0.8639\n",
            "Epoch 187/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3178 - accuracy: 0.8582 - val_loss: 0.3144 - val_accuracy: 0.8810\n",
            "Epoch 188/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2708 - accuracy: 0.8755 - val_loss: 0.2727 - val_accuracy: 0.9048\n",
            "Epoch 189/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3052 - accuracy: 0.8684 - val_loss: 0.3034 - val_accuracy: 0.8707\n",
            "Epoch 190/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2680 - accuracy: 0.8882 - val_loss: 0.2943 - val_accuracy: 0.8946\n",
            "Epoch 191/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2810 - accuracy: 0.8660 - val_loss: 0.2658 - val_accuracy: 0.8946\n",
            "Epoch 192/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2313 - accuracy: 0.8979 - val_loss: 0.2790 - val_accuracy: 0.8673\n",
            "Epoch 193/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2825 - accuracy: 0.8734 - val_loss: 0.3357 - val_accuracy: 0.8605\n",
            "Epoch 194/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2626 - accuracy: 0.8778 - val_loss: 0.2724 - val_accuracy: 0.8844\n",
            "Epoch 195/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2473 - accuracy: 0.8939 - val_loss: 0.2999 - val_accuracy: 0.8776\n",
            "Epoch 196/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3057 - accuracy: 0.8630 - val_loss: 0.3001 - val_accuracy: 0.8912\n",
            "Epoch 197/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2523 - accuracy: 0.8897 - val_loss: 0.3159 - val_accuracy: 0.8673\n",
            "Epoch 198/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2519 - accuracy: 0.8897 - val_loss: 0.2790 - val_accuracy: 0.8776\n",
            "Epoch 199/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2701 - accuracy: 0.8851 - val_loss: 0.3069 - val_accuracy: 0.8673\n",
            "Epoch 200/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2675 - accuracy: 0.8787 - val_loss: 0.3185 - val_accuracy: 0.8605\n",
            "Epoch 201/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2626 - accuracy: 0.8837 - val_loss: 0.2985 - val_accuracy: 0.8844\n",
            "Epoch 202/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2555 - accuracy: 0.8721 - val_loss: 0.2866 - val_accuracy: 0.8878\n",
            "Epoch 203/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.2484 - accuracy: 0.8836 - val_loss: 0.3081 - val_accuracy: 0.8741\n",
            "Epoch 204/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2686 - accuracy: 0.8961 - val_loss: 0.2941 - val_accuracy: 0.8878\n",
            "Epoch 205/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2779 - accuracy: 0.8811 - val_loss: 0.2867 - val_accuracy: 0.8810\n",
            "Epoch 206/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2651 - accuracy: 0.8878 - val_loss: 0.3027 - val_accuracy: 0.8707\n",
            "Epoch 207/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2573 - accuracy: 0.8706 - val_loss: 0.3019 - val_accuracy: 0.8741\n",
            "Epoch 208/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2507 - accuracy: 0.8901 - val_loss: 0.2990 - val_accuracy: 0.8878\n",
            "Epoch 209/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2507 - accuracy: 0.8822 - val_loss: 0.2873 - val_accuracy: 0.8776\n",
            "Epoch 210/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2871 - accuracy: 0.8614 - val_loss: 0.2819 - val_accuracy: 0.8980\n",
            "Epoch 211/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2511 - accuracy: 0.8967 - val_loss: 0.2962 - val_accuracy: 0.8776\n",
            "Epoch 212/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2737 - accuracy: 0.8781 - val_loss: 0.2804 - val_accuracy: 0.8776\n",
            "Epoch 213/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2678 - accuracy: 0.8910 - val_loss: 0.2973 - val_accuracy: 0.8776\n",
            "Epoch 214/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2393 - accuracy: 0.8926 - val_loss: 0.3051 - val_accuracy: 0.8844\n",
            "Epoch 215/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2647 - accuracy: 0.8744 - val_loss: 0.2854 - val_accuracy: 0.8741\n",
            "Epoch 216/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2905 - accuracy: 0.8742 - val_loss: 0.2787 - val_accuracy: 0.8946\n",
            "Epoch 217/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2588 - accuracy: 0.8955 - val_loss: 0.3144 - val_accuracy: 0.8639\n",
            "Epoch 218/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2483 - accuracy: 0.8898 - val_loss: 0.2597 - val_accuracy: 0.8946\n",
            "Epoch 219/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2908 - accuracy: 0.8771 - val_loss: 0.3002 - val_accuracy: 0.8878\n",
            "Epoch 220/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3007 - accuracy: 0.8802 - val_loss: 0.2538 - val_accuracy: 0.9048\n",
            "Epoch 221/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2600 - accuracy: 0.8866 - val_loss: 0.2780 - val_accuracy: 0.8980\n",
            "Epoch 222/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2496 - accuracy: 0.8913 - val_loss: 0.2926 - val_accuracy: 0.8605\n",
            "Epoch 223/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.2770 - accuracy: 0.8777 - val_loss: 0.3050 - val_accuracy: 0.8844\n",
            "Epoch 224/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2758 - accuracy: 0.8783 - val_loss: 0.2654 - val_accuracy: 0.8878\n",
            "Epoch 225/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2411 - accuracy: 0.8991 - val_loss: 0.2845 - val_accuracy: 0.8707\n",
            "Epoch 226/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2796 - accuracy: 0.8804 - val_loss: 0.3421 - val_accuracy: 0.8605\n",
            "Epoch 227/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2933 - accuracy: 0.8735 - val_loss: 0.2593 - val_accuracy: 0.8844\n",
            "Epoch 228/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2919 - accuracy: 0.8697 - val_loss: 0.2668 - val_accuracy: 0.8844\n",
            "Epoch 229/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2682 - accuracy: 0.8705 - val_loss: 0.3283 - val_accuracy: 0.8605\n",
            "Epoch 230/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2225 - accuracy: 0.8947 - val_loss: 0.2704 - val_accuracy: 0.8980\n",
            "Epoch 231/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2610 - accuracy: 0.8778 - val_loss: 0.2658 - val_accuracy: 0.8946\n",
            "Epoch 232/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2566 - accuracy: 0.8874 - val_loss: 0.3057 - val_accuracy: 0.8912\n",
            "Epoch 233/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2790 - accuracy: 0.8925 - val_loss: 0.2915 - val_accuracy: 0.8741\n",
            "Epoch 234/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2750 - accuracy: 0.8684 - val_loss: 0.3017 - val_accuracy: 0.8605\n",
            "Epoch 235/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2740 - accuracy: 0.8746 - val_loss: 0.2760 - val_accuracy: 0.8639\n",
            "Epoch 236/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2394 - accuracy: 0.8910 - val_loss: 0.2881 - val_accuracy: 0.8776\n",
            "Epoch 237/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2659 - accuracy: 0.8890 - val_loss: 0.2780 - val_accuracy: 0.8707\n",
            "Epoch 238/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2909 - accuracy: 0.8707 - val_loss: 0.2684 - val_accuracy: 0.8844\n",
            "Epoch 239/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2854 - accuracy: 0.8956 - val_loss: 0.2962 - val_accuracy: 0.8639\n",
            "Epoch 240/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2672 - accuracy: 0.8765 - val_loss: 0.2904 - val_accuracy: 0.8776\n",
            "Epoch 241/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2827 - accuracy: 0.8813 - val_loss: 0.2918 - val_accuracy: 0.8810\n",
            "Epoch 242/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2328 - accuracy: 0.9045 - val_loss: 0.3041 - val_accuracy: 0.8741\n",
            "Epoch 243/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2153 - accuracy: 0.9021 - val_loss: 0.3035 - val_accuracy: 0.8878\n",
            "Epoch 244/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2321 - accuracy: 0.9000 - val_loss: 0.3092 - val_accuracy: 0.8810\n",
            "Epoch 245/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2393 - accuracy: 0.8902 - val_loss: 0.3028 - val_accuracy: 0.8878\n",
            "Epoch 246/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2408 - accuracy: 0.8868 - val_loss: 0.3148 - val_accuracy: 0.8741\n",
            "Epoch 247/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2965 - accuracy: 0.8621 - val_loss: 0.2861 - val_accuracy: 0.8776\n",
            "Epoch 248/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2163 - accuracy: 0.9202 - val_loss: 0.2807 - val_accuracy: 0.8912\n",
            "Epoch 249/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2425 - accuracy: 0.8938 - val_loss: 0.2745 - val_accuracy: 0.8912\n",
            "Epoch 250/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2174 - accuracy: 0.9043 - val_loss: 0.2903 - val_accuracy: 0.8741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "32rKbdtmOT15",
        "outputId": "6702d2f9-edf2-4e87-a9a8-dc1ddd553844"
      },
      "source": [
        "def plot_graphs(history, string):\r\n",
        "  plt.plot(history.history[string])\r\n",
        "  plt.plot(history.history['val_'+string])\r\n",
        "  plt.xlabel(\"Epochs\")\r\n",
        "  plt.ylabel(string)\r\n",
        "  plt.legend([string, 'val_'+string])\r\n",
        "  plt.ylim([0,1])\r\n",
        "  plt.grid()\r\n",
        "  plt.show()\r\n",
        "  \r\n",
        "plot_graphs(history, \"accuracy\")\r\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUVfrHP2dKei+kFxIg9N6VpiKCXVmxl7Xsz7Xrurqru7Ku7rqy6xZXZS2r4lpARUVAUIQA0nsJJQTSe5tkUiaZzNzfH2cmk5CAATMEmPN5njwzc++Ze98zmTnf877vKULTNBQKhULhueh62gCFQqFQ9CxKCBQKhcLDUUKgUCgUHo4SAoVCofBwlBAoFAqFh6OEQKFQKDwctwmBEOK/QogyIcT+E5wXQoh/CSGyhBB7hRAj3WWLQqFQKE6MOz2C94DLTnJ+JtDX8Xcf8IYbbVEoFArFCXCbEGiatg6oOkmRq4EFmmQzECKEiHGXPQqFQqHoHEMP3jsOyG/zusBxrPj4gkKI+5BeA76+vqMSEhJO64Z2ux2dzrPSIp5YZ/DMeqs6ewanW+fMzMwKTdMiOzvXk0LQZTRNexN4E2D06NHa9u3bT+s66enpTJ06tRstO/vxxDqDZ9Zb1dkzON06CyFyT3SuJ6W0EGjbtY93HFMoFArFGaQnhWAJcLtj9NB4oEbTtA5hIYVCoVC4F7eFhoQQHwNTgQghRAHwHGAE0DRtPrAcmAVkAQ3AXe6yRaFQKBQnxm1CoGnaTT9yXgMecNf9FQrF+YXVaqWgoACLxdJ6LDg4mIMHD/agVWeeH6uzj48P8fHxGI3GLl/znEgWKxQKRUFBAYGBgSQnJyOEAMBsNhMYGNjDlp1ZTlZnTdOorKykoKCA3r17d/manjXuSqFQnLNYLBbCw8NbRUDRESEE4eHh7bymrqCEQKFQnDMoEfhxTuczUkKgUCgUHo4SAoVCoegiAQEBPW2CW1BCoFAoFB6OEgKFQqE4RTRN48knn2Tw4MEMGTKEhQsXAlBcXMzkyZMZPnw4gwcPZv369dhsNu68887Wsn//+9972PqOqOGjCoXinOMPX2dwoKgWm82GXq/vlmsOjA3iuSsHdans4sWL2b17N3v27KGiooIxY8YwefJkPvroI2bMmMEzzzyDzWajoaGB3bt3U1hYyP79cmsWk8nULfZ2J8ojUCgUilPkhx9+4KabbkKv1xMVFcWUKVPYtm0bY8aM4d1332Xu3Lns27ePwMBAUlJSOHbsGA899BArVqwgKCiop83vgPIIFArFOYez5362TSibPHky69atY9myZdx55508/vjj3H777ezZs4eVK1cyf/58Fi1axH//+9+eNrUdyiNQKBSKU2TSpEksXLgQm81GeXk569atY+zYseTm5hIVFcW9997LPffcw86dO6moqMBut3P99dfzwgsvsHPnzp42vwPKI1AoFIpT5Nprr2XTpk0MGzYMIQQvv/wy0dHRvP/++8ybNw+j0UhAQAALFiygsLCQu+66C7vdDsCf//znHra+I0oIFAqFoovU1dUBcvbuvHnzmDdvXrvzd9xxB3fccUeH952NXkBbVGhIoVAoPBwlBAqFQuHhKCFQKBQKD0cJgUKhUHg4SggUCoXCw1FCoFAoFB6OEgKFQqHwcJQQKBQKhRs42d4FOTk5DB48+Axac3KUECgUCoWHo2YWKxSKc49vnoaSffjaWkDfTc1Y9BCY+dIJTz/99NMkJCTwwAMPADB37lwMBgNr1qyhuroaq9XKCy+8wNVXX31Kt7VYLNx///1s374dg8HAK6+8wrRp08jIyOCuu+6iubkZu93O559/TmxsLLNnz6akpASbzcbvfvc75syZ85OqDUoIFAqFokvMmTOHRx99tFUIFi1axMqVK3n44YcJCgqioqKC8ePHc9VVV53SBvKvvfYaQgj27dvHoUOHuPTSS8nMzGT+/Pk88sgj3HLLLTQ3N2Oz2Vi+fDkxMTGsXLkSgJqamm6pmxIChUJx7uHouTeewWWoR4wYQVlZGUVFRZSXlxMaGkp0dDSPPfYY69atQ6fTUVhYSGlpKdHR0V2+7g8//MBDDz0EQP/+/UlKSiIzM5MJEybw4osvUlBQwHXXXUffvn0ZMmQIjz/+OE899RRXXHEFkyZN6pa6qRyBQqFQdJGf/exnfPbZZyxcuJA5c+bw4YcfUl5ezo4dO9i9ezdRUVFYLJZuudfNN9/MkiVL8PX1ZdasWaxevZp+/fqxbt06hgwZwrPPPsvzzz/fLfdSHoFCoVB0kTlz5nDvvfdSUVHB2rVrWbRoEb169cJoNLJmzRpyc3NP+ZqTJk3iww8/5KKLLiIzM5O8vDzS0tI4duwYKSkpPPzww+Tl5bF371769++Pn58ft956KyEhIbz99tvdUi8lBAqFQtFFBg0ahNlsJi4ujpiYGG655RauvPJKhgwZwujRo+nfv/8pX/OXv/wl999/P0OGDMFgMPDee+/h7e3NokWL+OCDDzAajURHR/Pb3/6Wbdu28cQTT2AwGDAajbzxxhvdUi8lBAqFQnEK7Nu3r/V5REQEmzZt6rScc++CzkhOTm7dzN7Hx4d33323Q5mnn36ap59+ut2xGTNmMHHixG7Pi6gcgUKhUHg4yiNQKBQKN7Fv3z5uu+22dse8vb3ZsmVLD1nUOUoIFArFOYOmaac0Rr+nGTJkCLt37z6j99Q07ZTfo0JDCoXinMDHx4fKysrTaug8BU3TqKysxMfH55TepzwChUJxThAfH09BQQHl5eWtxywWyyk3euc6P1ZnHx8f4uPjT+maSggUCsU5gdFopHfv3u2OpaenM2LEiB6yqGdwR53dGhoSQlwmhDgshMgSQjzdyflEIcQaIcQuIcReIcQsd9qjUCgUio64TQiEEHrgNWAmMBC4SQgx8LhizwKLNE0bAdwIvO4uexQKhULROe70CMYCWZqmHdM0rRn4BDh+fVYNCHI8DwaK3GiPQqFQKDpBuCsDL4SYDVymado9jte3AeM0TXuwTZkY4FsgFPAHLtE0bUcn17oPuA8gKipq1CeffHJaNtXV1Z1016DzEU+sM3hmvVWdPYPTrfO0adN2aJo2urNzPZ0svgl4T9O0vwkhJgAfCCEGa5pmb1tI07Q3gTcBRo8erU2dOvW0bpaens7pvvdcxRPrDJ5Zb1Vnz8AddXZnaKgQSGjzOt5xrC13A4sANE3bBPgAEW60SaFQKBTH4U4h2Ab0FUL0FkJ4IZPBS44rkwdcDCCEGIAUgnIUCoVCccZwmxBomtYCPAisBA4iRwdlCCGeF0Jc5Sj2BHCvEGIP8DFwp6amDSoUCsUZxa05Ak3TlgPLjzv2+zbPDwAXuNMGhUKhUJwctdaQQqFQeDhKCBQKhcLDUUKgUCgUHo4SAoVCofBwlBAoFAqFh6OEQKFQKDwcJQQKhULh4SghUCgUCg9HCYFCoVB4OEoIFAqFwsNRQqBQKBQejhIChUKh8HCUECgUCoWHo4RAoVAoPBwlBAqFQuHhKCFQKBQKD8djhOBQSS2r86yoDdAUCoWiPR4jBD8cqWDBgWZqG1t62hSFQqE4q/AYIYgN8QWg0NTYw5YoFArF2YXHCEGcEgKFQqHoFI8RgnivOkaKTAqrG3raFIVCoTir8BghCMtcxGLvuZRVmXraFIVCoTir8BghEP4RANRWlvSwJQqFQnF24TFCgF84AA2m0h42RKFQKM4uPE4IrObyHjZEoVAozi48SAhkaEjXWIXFauthYxQKheLswYOEIAyAcGGmuMbSw8YoFArF2YPnCIFPCHZ0hAoz+VVqCKlCoVA48Rwh0OloNgYShpmssrqetkahUCjOGjxHCACbMYhoQx1Hysw9bYpCoVCcNXiUEFiNQcR4NZBZqjwChUKhcOJxQhCuM5NZalbLUSsUCoUDjxOCIHsNZksLpbVNPW2OQqFQnBV4nBD4WGsQ2MksVXkChUKhADcLgRDiMiHEYSFElhDi6ROUuUEIcUAIkSGE+Mid9jR7BSM0O0E0KCFQKBQKBwZ3XVgIoQdeA6YDBcA2IcQSTdMOtCnTF/gNcIGmadVCiF7usgfAagwEoI+/hUMlSggUCoUC3OsRjAWyNE07pmlaM/AJcPVxZe4FXtM0rRpA07QyN9qD1RgEwPDwFg4W17rzVgqFQnHO4DaPAIgD8tu8LgDGHVemH4AQYgOgB+Zqmrbi+AsJIe4D7gOIiooiPT399Cyy+UnDmnM4XBrNqtVrMOjE6V3rHKGuru70P69zGE+st6qzZ+COOrtTCLp6/77AVCAeWCeEGKJpWrvdYzRNexN4E2D06NHa1KlTT+tm675vBgQTo1poKYGEgaNJiw78Ceaf/aSnp3O6n9e5jCfWW9XZM3BHnd0ZGioEEtq8jncca0sBsETTNKumadlAJlIY3IJd7wUhCcTapBnO8JDVZmfukgwK1DaWCoXCA3GnEGwD+gohegshvIAbgSXHlfkS6Q0ghIhAhoqOudEmCO9DQH0eXnpdqxAcKjbz3sYcVuxXu5cpFArPw21CoGlaC/AgsBI4CCzSNC1DCPG8EOIqR7GVQKUQ4gCwBnhS07RKd9kEQHgfdFVH6dvLn4OOkUO5VfXysVJ5BAqFwvNwa45A07TlwPLjjv2+zXMNeNzxd2YI7wNNtYxOsrE8W3oETgHIVctTKxQKD8SjZhYDEJ4KwOiASsrNTVTUNZHnEAK1T4FCofBEPFAI+gAwwEtOWThYXNsaGiqobsBmV4vRKRQKz8LzhCA4AQy+xFtzASkEeZUNGHQCq02jyNTYwwYqFArFmcXzhECnh+jB+FTsIzrIhz35NRTXWhiVFMq/jK/StOW/PW2hQqFQnFE8TwgAYoZD8V4GRvuTfrgMTYPJfUKZqduKMe+HnrZOoVAoziieKQSxw6HZzPXJTdQ32wC4MLoFo7Bhr3fv6FWFQqE42/BMIYgZDsDlEWV8cPdY7pyYzEBfuaqF1lDVWkzTNH6zeB/bc6o6vYxCoVCcD3imEET2B4MPFO9mUt9I5l41CKNZLjvhZTVhamgGoKbRysdb81h10K2LoioUCkWP4plCoDdAr4FQshfsNijYATV5AIRiZm1mOQBlZrmdpVMYFAqF4nzEM4UAIKIfVB6F/Yvh7Yvg4FIA/EUTaw8UgM2KcdO/8MKKqcHaw8YqFAqF++iSEAghHhFCBAnJO0KInUKIS91tnFuJ6AO1hZC3Ub4u3t16Kie/API20Xv3y0zUZVCtPAKFQnEe01WP4OeaptUClwKhwG3AS26z6kwQ7ljt+tAy1zGdEYBmc0Vr0jiIBmoalUegUCjOX7oqBM5tvGYBH2ialtHm2LlJhEMI6kpdx6IGAhBgr6W+Rg4jDRL1yiNQKBTnNV0Vgh1CiG+RQrBSCBEI2N1n1hkgLIVWLes7Qz7GDAMghDrqTBUABNJIdYMVuVCqQqFQnH90dRnqu4HhwDFN0xqEEGHAXe4z6wxg9JXrDtXkwZh7IPkCSJkKOxcQKsw01Mo1h4JEPc0tdixWO75e+h41WaFQKNxBV4VgArBb07R6IcStwEjgn+4z6wwR0UcKQfRg6HcpWGXjH0od1jrp8AQil6aubmjG18u3x0xVKBQKd9HV0NAbQIMQYhjwBHAUWOA2q84UsSMhKB4CY+Rroy+a0Y9wXR22RjnTuJeXcy6BShgrFIrzk64KQYtjN7GrgX9rmvYaEOg+s84QU56C+38A4cp7C98wYrwasTdIIYjyUpPKFArF+U1XQ0NmIcRvkMNGJwkhdIDRfWadIQxe8q8tfqFENdUjLFIIwvQyXFStPAKFQnGe0lWPYA7QhJxPUALEA/PcZlVP4htGmK4OX5vc2D5ISCEwNSqPQKFQnJ90SQgcjf+HQLAQ4grAomnauZ8j6IyAKEJslQQLuX1lIPJR5QgUCsX5SleXmLgB2Ar8DLgB2CKEmO1Ow3qMsBRCmksJcQiBrsmMr1GvcgQKheK8pas5gmeAMZqmlQEIISKBVcBn7jKsxwhLQaChRwOvQGg2E+4rVI5AoVCct3Q1R6BzioCDylN477lFWIrreUgiALG+LVTXK49AoVCcn3TVI1ghhFgJfOx4PQdY7h6Tepi2QhCaBGUZJPtb2V9j6TmbFAqFwo10SQg0TXtSCHE9cIHj0Juapn3hPrN6EL8w8AkGS02rR5AU0MLK4sYeNkyhUCjcQ1c9AjRN+xz43I22nB0IIb2Col2tQpDga6Wm0UpdUwt2TSPI59yfQqFQKBROThrnF0KYhRC1nfyZhRC1Z8rIM44zPOQQgmgfmR/4cHMuo/74HRlFNa1Fl+wpYvyfvsditZ1xMxUKhaI7OKkQaJoWqGlaUCd/gZqmBZ0pI884YanyMSQJgF5GmR/4bEcBVpvGm+uOtRbdnlNFSa2FnMr6M26mQqFQdAfn58ifn8ron8M1b7R6BOEGKQRHyuoAWLq3mIJquSppbqV8PFqmhEChUJybKCHojKAYGH4zeAeBzkCA1YSXXn5UF/aJwGbXWH1IjqbNdXgCx8rruu/+5lKoyu6+6ykUCsVJUEJwMnQ6CE5AmHKIDfEBYOaQaPy89GRX1NNis1NQLUcTHauo775dzJY/AYtu655rKRQKxY+ghODHCOsN1TnEhcpNaYbEBZMU7k9ORT3FNRZa7LLx31dYw8SXVvPJ1ryffs/SDKjK+enXUSgUii6ghODHCE2G6mziQ/ww6gVp0YH0jvAjp7KhNT+QFhVIVlkdxTUWVh0sO/n1HGSVmWlobul4wmqB6hxoNoPl/B2YpVAozh6UEPwYob2hsZr/Gx/Ogung/Y8BDAhqJr+qgaPldSSJEn4TuAyQnsHOvOofDRE1tdi44tUfeG9jTseTVcdAk9tkYi7u3rooFApFJ7hVCIQQlwkhDgshsoQQT5+k3PVCCE0IMdqd9pwWockA9NaVM8GYBXWlDDYW0WLX2Hi0gtnGDUwtmE8kNYxIDKGqvpnsipOPICo3N2Gx2smtaOh4siLT9by2sBsrolAoFJ3jNiEQQuiB14CZwEDgJiHEwE7KBQKPAFvcZctPIqy3fKzOBlMuAEnGagDWH6kgxUeOFnr9qmj+dO0QAHbkVp/0kqW1cvvLktpO1i9qJwRFP8VyhUKh6BLu9AjGAlmaph3TNK0Z+AS55/Hx/BH4C3B2rurm8AiozgGTTARHaZUANDTbGBYsRw2NCW8mLSqQIB/DjwpBmUMASjpbyK4iEwKi5PNaFRpSnGd018g6RbfS5bWGToM4IL/N6wJgXNsCQoiRQIKmacuEEE+e6EJCiPuA+wCioqJIT08/LYPq6upO670TjcFUZGwkuOYA/oDp6E58DYMJ9REENcrwTeb2dIqKfekTpLFybwGXhlWiE6LT6/2QK/c2KKgyd7BnVPZOmr3iCDRaqDi0jUzt1O1ty+nW+VzHE+t9ttc5ruBr4gqXs3XcG912zbO9zu7AHXV2pxCcFCGEDngFuPPHymqa9ibwJsDo0aO1qVOnntY909PTOa33Hh1ArGaCZukJxAVovHHbGOJD/QhaIPMB/WIC6Td1KtXBBTy2cA/ByYMZxSHoPQmAjVkVVDdYuXxoDFtWHIKDR6m3wvgLJuFj1LvutaUaUqZCgZVQbxubG6N5YFoqgae50N1p1/kc56yqd1MdNFTKZc3dyFlV5874+gvIKmLq+JHg0z0r1Jz1dXYD7qizO0NDhUBCm9fxjmNOAoHBQLoQIgcYDyw5KxPGieOgYBu0OJairi1kalov+kT4Qr1juKhjhM/FA6Lw0uvY+PV/4f0rePy1RWw6WskjC3fz+KLdVNc3U9omN9AuPKRpYKmhXh/EsaZgcnOOMH/tUVbsLzlTNe0Sjc02PttR0H0T6M53NvwD3rm0p63oeSyOxRpV7uusw51CsA3oK4ToLYTwAm4EljhPappWo2lahKZpyZqmJQObgas0TdvuRptOj+RJOIeHEhQPNQXyeX25a6hnbTFYLQR56ZjUN4LG0qMA2Kqyue2dLZSbm2hqsbNwez5ltU04o0btEsZNZtBsfJ1Zz8YKb2J1JgK8DezON3UwqScb4a/3FvGrT/eQWdqNy2qcz9QUQl2pio8758XUFvSsHYoOuE0INE1rAR4EVgIHgUWapmUIIZ4XQlzlrvu6hYRxIBwfVdJEsJiguR7Mjp66zijH//99ILyUyLyY1VzXV5b/9YQAdEIwISWc8SlhfLApl6KaRlIjAwDIKKp1NfQW+bivAmITUgiy1zAm3pddee2FwNTQzPDnv2PVgVL3170TjpXLcFh1g9q+s0tYagANrJ0MF/YkmhxCUKOGRZ9tuHUegaZpyzVN66dpWqqmaS86jv1e07QlnZSdelZ6AyDjmTHD5POkCfKxtsglBFGD5PDShkoQOsJyltHHxwxAnK6aPXF/4d3UtdwxOpLwmv0cK6/j116LGShyeHHZAW6Yv4kys6XVda6w+dEraQAAUyNqOVRS224W8oHiWmoarXyyrW0u3sWBolqyytzXW8+ukNc2NVjddo/zCofA0+zhK9Sq0NBZi5pZ3FUGXg3RQyCin3y98hnY49jCOW6kfPQKgEHXyHWCnF/28sP4lu3Cp2IflzR8w+dec0kSpVxa8R6zvTZj16DZZuflFYeZ96WcSlEvAkgdMAqAUf7l2DX4YlchxTUyR3HU0SNfd6Qcs0U2xja7xrK9xbTY7Dz48U5+s3ivvJa183CE1Wbn2tc3sGzvqQ9RdU6Yq208y4Sgrhz2fdbTVnTE2QA2e3goTYWGzlqUEHSVCx+D//tB7l4mdHBkJRz4Up5zegspUyEiDZpqXBPDstfKx7oyjOYCjMLGBboMABKMtQR6G7igTzif7SggK0/+QGKiY/CNSQMEKUI21M98sZ8pL6fzenoWRx29/eYWO/9Ze4zKuiZWZpTwwEc7+WBzLsfK68koquW7A6U8vLqBrDJzh+rszK1mV56JlRmnloi22TVyHGssmRrPstDQrg/g87uhoaqnLWlPqxB4uEegQkNnLUoITpWgWPjlFrh5kXztF+6adNZvhuu5s/fnbATqymTCEJjoEIJhIRb+fP0Qnr18IJP6RvDMxTEAzL5gEBh9ISQRv5os/nPbKF67eSQX9Aln3srD7MitZlBsEEnhfvx7TRbXtOnZv54uk9QNzTb++0M2Ng2+2t3RFV9zuByA/W223ewKRaZGmltkgrzmND2CLccquevdrVht9tN6/wlxfL40nnxC38nIr2rggY92dr4g4OnSqEJD2KyuHIlaOuWsQwnB6RDZTzb6/S6DyP6QdAHMnAdDbnAtSQHgFeh6Xl8uxQCY6S+9hV7CxBVDYxkQHcgHV4eT6Csb1nEDHXsmR/SDikxmDIrm8qExPHRxXzRNLnndt1cA3zwyiZevH0p+VSPL9kkhKDc3td5y0zE572Hp3mI0TSO3sr41MZ1+WNqSXVFPXVPXG71jbdZROl0hWHWwlDWHyznanZv5gEsILG3EzZQHWd93+RJrM8tZtreYA0XdtPKrrUWuJAvnT2iovvLU3+MMC+m9pEfg6SOozjKUEPwUblgAt34OeiOMuw+MPi6PAFy5A5CNgGPXMb3FEbpwJpv3LoR/j4bi3TLs5BSQiH5QkQV22XMeFh9CsK+cWJYaGYCfl4HZo+Lp00uOQJo1JBqAofHBeBnkvzbaX5BdIUNFv/xwJ9e+voHfLN7HoRIz05P06DTbSRu9dsNUV7+A37Z/AxDoYzjtZLFz+e6Dxd28zHad9HJak7MAm16DT27pcsNTaJJ5mKLOlv84HZra1PF88AjKM2FeKuRvA7tN/nWFJoc4R6SBtb69WCt6HCUEPwWDtwzhtMXL37VWUMJY+egcemo+LkRjMcn9B/YvBjTI3wI+wXJnNJCeR0sj1MjRQXqd4MK+EQCkOhp/nU7wq0vTGBYfzG9mDkAImJASzoBoKSY3pnnh56XnV5/uIaOolsQwPz7emseIWB/mV9/LXfoVvLj8ILP+uZ6HPt7F818fIL9KNtSLdxYw9A/f8v7GHCkIu/5HVN4yQvyMpEYG/KhH0Nxix+QYYlprsXLVv3/gjfSjrUJwqLhj7uIn0RoaaiME9RXyM7R0nIvRjiOr4NM7GXfoZXyxcMG3V0JeN6yD2Pa+54MQVGQCGlQchk/vgC9/2bX3OT2CKMe6k6Zu2MCpp7BaoGRfT1vRrSghcAehjvBQ/Bj56Ewmd0bVUTi2Rj435UkhcBLZXz6WHWg9dHH/XgD0j3aFnS4bHM1XD15IQpgfH987nvunpjIiMZRAbwODI/TcPyWVQyVm/L30LHt4Evv/MIMvrg1C31zLJK9M9uSbMOgFe/JN/G9LLrPnbySrrI4PNufS2GzjuSUZvLVqD5iLCbYUccPoBEL8jNQ0WvnLikMs2VPEl7sKmTJvTTtxeOmbQ1zyyloam2089slu9hbUsCKjhNwq2SAeLHEJwXsbspk6bw3bcn5Cotc5y7ttb9OZLzA7RKLskMtzaMv3cyHjCyaZviBZlBJenyVnk4OcQLjlzdMLZzSeZ0Lg3CPDXAzFe+RfV3D+T5y/ifJD3W/bmWL3/+DNqe3/t+c4SgjcQVhvOckscbx0hYfe6DoXKBPCrY38zgVgazP6xifE9Tx6qLxOvqtnes3wOFY8OokUx4S04xmvO0TIykf4ddR2vnzwAgw6wb2TU7gneDuPDmogwNtAgLcBCncAMNo7n79O9earKaWs+/U0vn7wQmx2uOu9rezKM/HY9H5cOSyW5Wvk6KdgUc/PR8kQVVV9M++sz+YPSzJY+O1aLjUt4s21Wdz81mY+31HA4l0FVNQ186tP99CQuYaUUAN7C0xYrHYMOsGhNqGhpXuLyals4Oa3Np9e7sDqmofRrhfuFII6Rxjuw9my0T8eR5hOj53ejpFaNDpEac/H8M2T7f4PXaatKJ0rOYImM1Qe7fyc0+uqLZaf2fFe7gmv6fhfx42U3+nS/Scu+93vYc2fum7vmaY6B+wt0ts8T1BC4A7G/QJmvSx79w9uhQFXus45w0XOx90fg3+kSxh82wiBlx/EDoe8za2HdDpB/+ggOUTy+B5qQxUsuBr2fITfxr+SGuEPgI9e8Ix9Pr2ZQAEAACAASURBVPfovnaVLdoJgL+lhNkFLyEW3wvNDaRFBzJvtkxADxNZ3Fn2Mi9dM5ArYl2NWLStlBBfIwXVjTTb7FTWN/OLuvk8Y/yIxenb2Hi0khc/+4GUxgwSDNXs2b+Hj71e5O/99reaPLFPBGXmJvKrGrBYbewpMHHdiDg0DT7ecuKwwWtrsliwKafjifo2vfwTeQQtzTLMVnZcb9Qmf9RaeF8A+opC1+cJrlzO7g9PaNcJaScE54hHsP5v8NZFnXtAzs+iNEN2YCw1XauXMzTkFy6/66UHTlz28DeQufLU7T5TOL1LZ4ejpuCcnySnhMAdxI6A0T93vfaPdD1PutDxeIF8bKqBPtNd4aS2HgFIr6JwB2Svlwk6gGPpMK8PLH1U/lgbq+X5nB/AboUhP4OaPLnsBUBtIcLagKjOcV23cCf4hsrnBdtAs7XGPaf178Vt45P4U+hS/A8uxL82i3v6t8kHmHJbk9YA0wLymKqXIYIUXRG3jEvkbeNfWew9lxW+vyPV0cNOtR5pfc/ljsT2pJfX8OBHO7HaNC4fGsP0gVF8vrOAppaOSUhTQzP/XHWEyh/ehY9ubF+mzrVXdFlZm6U32noETq+g6rjebn0ZoNEYKsU4Te8QgsYq1hwqoyDP8TlmfAnWxg52dUqTI+x1khzBgaJafrN4Hy3dMIz2QFEtNruj4S7eA189IAXudKjMknZ3Nh/DKQQle13H2u6bkfW9TCgfj9Mj8A6SeYLSjBPf31zaXtjPNpzfI2do6Iv/g68e7Dl7ugElBGcCg5er0R10Ddy6GAbPdiWR+053jTZqmyMASJwge17vXwHvXAILb4PP75VJ6R3vwdLH4KMb5fnNr4PRHyY9Id97LF0+VjoaYKcQWGrksWE3t7+Xw0sA+OOUQAY1OISncAdUHHGFtfK3cknhv/FGhrReTd2KZvQD4I0ZQbx4WTwjdFlYfHrhb63iqYGyQfGvyiDc3wujXnDtiHheuWEYk/pGYDu8kvG6g4xOCmPOmASqG6z8/ssMKuuasNk1LFbZ4H+9p4hmm50Jdd9D5jeMnruUI6WOBrfeJQQ7D2eztbgFzW5r7ZHba0tcvbbGamiootDUyC1vb6akUH4uFQFy1vgQoyxnb6jm1dVHqC7Nl7PGm2ohZ4Pr8zq8Al6f0LHBLM2Al5KgYIfLI/AO6hAa+mZ/MR9vzWNn3k+LNReZGrn81fV8k+MQ64NLYdf/oOwkje3JcC6qWNPJEibORrDtuknO8FBNAXw0B1Y91/F9bT+HXgPlezoTmuYG2TmqLz95TqamB2cnm4+br2LKa9298FxFCcGZwr8XCD34RUCfi0FvcBzTQeo011r1vsd5BAnjASFzDeMfgILtYPCBu76Rs513vAv5m2XcNW+TXAspsj8EJ7iEoMIhBI1V8geZ8YV83e9SWS4oDgJjW/MGAGx7C4SQwlK4A8oPQ/xoKVSb32Bo7gKm63YQ6G3Av2IfImUaeAUSVJ8NuRsRaPiMk17RQPMmAETZQcYmBpASEYCXQcd1I+OZd1kMrxn/xQu+HxLsZ2Ry30juvrA3i3bkM/rFVQx+biVjXlhFTYOVz3YWosfGEGSPM9xWznsbcwBoMsleqckQQS8vC6/vaeKtb3fjXDV2+abdFOcfc9Wv6hh/+/YwG7Iq2X1QhoryjdIri7VLj6ClroL9RbWEaVVYo2TCf8POPTKHUbIfPvu5TOQfnzA9li49rOJdsteoM4B/JFpzPUv3FrUuC1JQLb2L1YdcIoa18ZRn3mYU1aJpsCavRXoFzkbSmez+MZqOy1047j/v09XUHD9E2NzJQodOgd3wT+mR5m/p2IhbaqWY6g0QNVgeK+skPOQUGmfYycnOBZArv0ccXQN/HwRZq7pQuS7S0gxlB7tW1mmjxSTr2WaOULeRu/H05mucJkoIzhQBveSfrs1HHpoMiROltxDiEILjQ0P+4XDrZ3DH13DZn+CJg/DYPogeDJfMhatfh8teglF3yvK9J8sGPHUaHEtH39LYfh/kwp2waq68b+8p8hozX5ZJPKcQHFklx98PuUHuxZC1WoaZIvtLOzXZQ5+l30JahAFRdVQuvBfRR4pO9nopVsMdHoczMWi38uKFRt663bXlRPTe1/ETTaTac6G5AZ1O8LsrBrLikcn87gI/7u1Tg7mphTfXH2VPvokbEmrxF3LSXKyoZPHOQgpNjRTkO3pk4X0YESkYG61n4XpX+CJcM7Fhp+t1cfZ+vtglG7ziAvneuVtk46V31M9qrsTa0kIvTFQGybDRlr0H+N/mXNj+DrQ45hq0DbkB5G+Vj1XZsjHzCQbvAKqrq3jwo128vV7OJymolr3qNW2EIO/TpzH/6wKarV0cnw8cLpFhl0qLJicKOnvyBY7/p93WOhelHZoGSx6CVwa4RlK1NLV6V+ayHHbktem121pko+ft8FqdHm1tkRS8He/LMGhDpSss6aSpRnoDAL3kgoqdNrzO0BO4wkP1FfD1o7DxX/L12pfl46HlJ/pITp0d78H8ST8+K93a6BKoRpP08qwN0lts/omry2qarGvlUXh3lszVnCGUEJwpek+B1IvbH5v9Dsz+r3zuDA0d7xEA9LkEAqM6v+6IW2D8/TDxQYgbDQMcK3yPuB2aaokuWSWFwCgTx3z7rPwCX/43KRhDZsOAKyBulPzxVmXDF/dBr0FwxSvyeE2e7NWOuK3Vc2kMTuUi3S4m++fLPRmiBkJ4Xxlfzlkvl+4OSXT9+CPSAAirPURiuAwjUX5YNqihyQjNJifUAWgaadGB/Lz0JR7Le5CLA3J5I/0oep3g3mRXozksoBZjSy0Fr0wlZN87mDR/AsNjERYTj8Rn0d9bjupo0LyJ1puoLs2lSTNi0wQNq//GWu/HuH5QIObyAuyaQBccR73OtXOWoclEGGaMwkah1osGQwi9RDU5FfXyc4oeIj2x44XA2ROvygaLCc0nhBa9H+WVslF1bjRUUN2IQSc4XGpmzZrvaGmsxffYCgJt1bz0VddHKB0qMRMb7EOQF3y5uwjteI/g4xth8T0d37jhH7Kn3VQLBx0LArdZ/iFWVHK4pI234MilEDNUvg6MlaLgHEpqa4ILH5fndrwnR/44BcgpiCBDjAafjp8bdC4E+xfLzkfFEdlTztsIRj/I+k42njs/kA1nVye3OSnZJz0BkDkPu/XE3ljVMSmEdcfln9p6Ak5P4ciqUxsYYGuRIvLpnfDXfvDFLwANinadSm1+EkoIzhRTnoRrXmt/LDje1cD3GgAz/gwDrzm964cmw73fu5a4SBgDCeNJyF8iG9yUKfJ46X6Zd3BO7HHS7zLZw3t3luzRXflPmYeIk6ugMuGXUgQSxkF4Xyom/wkfYeXq2o8c9g+CiL6yN1q6X4qXEK7VWvtcIsXo0DLZONhtMsHm5Q83Oq5RsF3+sP6SBBv/DfmbETYr/+RlbtCt5sbkRpIq0inXgrFrgkmR9WxMfIvR+iwC9C3YQpLR+4WAuYSJ+3/Hy6FyUcAsLY4EYy0J+moafGMoFZGkankkUsrdAZsI16qpJpAPf3Eh/qEuwfWmicF+soeYZQmk0BZMlDDJRfdMuRCWQlNAPOu2bmPmP9fzx6UHyM/OdDWm1dIjKG7yZl2ehaaGWuJCfDlcauZwiZlo834+jPqIvoHNTEy/kdLXZhHZIhuT9Tv2sb/QFRpZtreYCX/+nso61xIiTjJLahkYG8TAcD1bjpZjNxVg0YwyD1R+GI58J/MZtjZhHksNrH8F0mZJAXcuoFjTXggynTkYu93VSDvnxQTFyr/aIpfXN/h6KQ4b/wVr/yIbM1uLLOPcnlKnk9/X6hyOLH6BvDeucwlGWyGoK5O94z0fuT7Pg0ul+E77LZjy8G0sksN7cze4QkXfPSfzZj/83ZW0P55Dy2D+hbIjAq7wqdkxLLalzedcsh9eHSVXAGgbGrOY2ie1zaVgyocPr4d186RneHBp5/d3YrdJO/4UI/8HAb2kgOsMDnHq5vW4ToASgrMFIWRj6xfWfdec8mu8m8plLyZulKtH1n9Wx7JRA2H8L2USr++lEO8QgD6XwOWvwORfy9cTH4IHtxE++CIKdHEkmbaA3luuyhreR5aJSIOx9zmeO4QgPBUmPQ6Hl8PK38geaMFWKX5Rg6T3ULgdDn4tG6lvn5Xv+9l7EJzAS8a3ebHo5+iz17JMfzFlhDCkZi0BpVvRz/oL3k/sJ/yexTK0Zm1AYMe/UiZLY/qOwGCt49LoekKjkwiOH4BdGCAshbT8RUTrqmnyiSQiwBv85cxtu84LgGmh8oe+9JidwpYQEow1FFbVoZny2FUXzPbaICJbSogM9Ob9jTn89Z0PALAlTIDqHDRTPtkNPtgN/oQamnntFrnsyHvrDvNXwxuMq/6alSO34i1aiKtzzVaNEZWsP1JBeW0jDdUlrNqfT3GNhTfXtw+5WLPW8UXNDYwLNnGDYT0jGjag16x8bx8hCyx9DLkpTv1xOaC3pScw9Wk5gCHnB9kAOryJYi2MVO8aDjkn/a14Ct6aBoAWMxyAakMEBMWg1RbRXLAHAqJlxyZhrPxOCD3aga/I/utUee+UqRSZGnl84W6sQYlQlY048AWJpd/LlWPB1asG2P0RvDpSiknUYDl2/+AS+X3pfwUAvco2uEJx29+V9m/4h7zfqrnw77GupHRVNlTnygb7qwfkscwV0quoOCxf1+TDa2PlwAsnG/8lvd6yAy77dAaHR9BGGOpKXAMzdv0PFt0OX/2yY2PeUCU7PSC/7+UHYcSt8rt+7xoYcy9MedqxLM1xITY3oYTgfKbPxewa8Rc5j2Hg1a7wU1onQgCylzXufplzcKI3wpi75ZwGJ0Lg5+1F/GWPydeRaTIJmDhBCs51b8p1l0AukwHSU5n0hPySb5kPq/4g7Rl6gzwfP0bOl9i/WLr9aLKnOvBqAh5cR9HspXDVv+EX61kedR9FWjiBdY4fycBrZAMeGH1caE3G/CNTZA9WV34AgmLxn/EsutnvwJSn0FdlcbFuJ5GxjhyNQwh0EVLULo+SHsExSyAWnwgSjbVE2isQ9hY+yTJQ55tAmlclC8YXs/XOUH4ZtIFyLZi/F6RJQao4zOrmAfRNiCLBX2N4QggjEkOI3PcmqbpiNAS6bW/SovfFrPli0mQIb1RwHSlbnsX4Sh/8/pnGrzJvJVUUYtn0Nve+u5GNR2XYy7z7C/xFE9NNn3JN+ev8xfgWAF/aLqQoaKjsKQfGAgKy18k62u2w9S0ZqowZBkPnyIEM718pwy5ApnEA8bpKjpbV0VJfLUNIDkoDZJhvp8mXUsKpLDrG0X2bMDuG3zJrHty1XH4fNr9G78Z9LI57Eqb+hm8zSli8q5DDzRFo1dnEW2V+Rvvu9zL+bi6VgxcQcPR72fu/5TOY+Rd57Zp8OTw7rDfEjyEpd6EM6cSNlkvDp/9Zlrt7Jdz+lezYbH1L1vl/11O/YA7pC1+RjXi/mTLUZMp15QYKtsuOiDN/UVMA+z+XzyuPujyCsFQZYm0bGjKXuhru+nLpXVhqOgxXLlv6B3j7Ytj8hvRawlLgyn/BoGshKAYu/6tc1BJc4VKQQuamxfqUEJzn1AanwZz/ybBN7AjZ4Iandl7Yyx9mvnTi88cz7CaZ6HYurhcUA/eulpPgnKRMk55C9DDp9Vz8OzmpqDpbeg06vSw34jbZu8r9AcbcIxuniQ/J9whB7OBJMPI2iBlKUpgfRZpssIlIa228gY7Db0EKhVeA7FEGxsge66BrYNB1rbkLo59DQPyc15WTyyIb5I+4nBDS+vTDt7mCZJ3sFUYlpjFj0nh0TSb49E7CFl1LWsMOmsc9QJY9tvX26xhNTGREa9z4F9GHeVS3iKW28VgSp0i7ki7gQfvjPOMlPa8Z3vuY0bicHba+/KXlJsK0ar73fpI/6N4mMHslLy47iKZp6HLXA5CcsxAddkKEYxtRr1heDXgEDL4w4la06CHYj8nZ4RvXrwJzMYusE9l8rBItvA/c/hUtNcWwcwHVBGEJ7k2gtYIWWwtVWz+BFgtfxTyCNu5+ttSE8rJ1DvNN4/i0NIYITAzQ5bGt0VHnsN5yhFnaTIS9hc32ASy0XQRCtHoYq0v9ENYGfISVFbYxCItJDrs1F0sh8AuXn0vUQPLCLsAW2SaUGevwdi58DJ3WIsXi+rfBN0z2xONGy8Y1Zaps7Le8AZnfQNVR/KsPMij/Y2xxY+TET1szbHvHde1cx/BgkyPhvnOBDN/EDJONfF2JFM3wPmiN1Xy9cTea0EkPoa4UqrLRDD7kaFFke8nvENlrIf2lVs+k5ohjguiKp2VDP/lJ1+/ASa8BcqVW54g0c4n0jtp6Kt2IEgJPYtbf4I4fiVmeCt4B8It1MP35E5eJHQ4P7ZCjn0A21NOfl6Gg4be4yqVOk8NjQXov170Jo+7o9JJ3XdCb1L6OkSdJE9ufdIy6shocazF5BcrcxsW/l6+D411lDV4yaQ4yeQmuyX/OkFbZAey+4fz5Z6NJ7p2K0OwMF1Ic+g0Y0n61WZ8g8A0l7uIHGDNSiuNRewxpg4bj5RvoGGFiYXrm8+zXknmq5T68BskQh6HPNEZMuYbhk64C/0j61Mkwzjv+d/NGy5U8aH2I+oQpIHT8vF8TV5T9h7IP7ibEfIR85OS8ZqNLBAcOGMA3JUF8c/EKSoY/xA7DSOy5m9i0bSvbv/uQFnT8PSeZG9/czM/mb2KjLY2H6+8CoMAehl9EIjrNxnX69fjtmM9Rkcgj2WNZmfAo23NreN12Ndss8fyjYjQ1PvIz/bo0gur6ZuYuyeDKV3+gJGEmud79eN56G9nOFWdLzHgbdOyqC2219VPbZADWrPkWm7lEhpcC5Jpa9RFDuehv6Xx+oF6KA7g6Gv1mUuefDL0nSfG5/m3ZSI+8zfU/mfIkNJqwLbwdm1cQNnREihrKEmbK747RMR/H+d1xJrBr8qUXsfsj+d3sPUV2XmqLpG1+oVhqKzFXFGHWhcih4HXSI7AEJnF505+43+tPcrDE989LT2XVXIoqa0lsPsqClulkXfwmPLjdNbquLXqjXGIm40s5YW//Yhme6jO9Y9luQAmBJ6E3uEI23UVIYue98JMx4lZ4dF/HEVLTn4d7Vsve5EkYGBvEgDRHD9E5Q9uJ45qlUVMdrx0Nzph7ZAJ88PXty/eeJDcZumSufO30LpxC0FCJLjyF60fFIxwT6sYbMmnRdIwdNrh9uO0X6+Ce78E7gOumTaQOXw6FTePl2UOlt6XZIGMxeks1C4PvJiQ4FP2Q66VnMvh6Hr2kH/dOToGgWAwt9TQJb3590yz6RQWw3Xs8vnd9BaHJDDAUcpNhDVHHZMhiZfzDEBhLZr/70XyC0bwCGJicgKnByv1fFfLCiixerJxMs2bAvPQZZhl2okucwJrfXcsfrx7ErnwTd/x3K8vt43mj5Uq+tF2Ib//paH4R/NX4H+x1FTzfdBNeej0vLDvAhqMVDIkLRiegBQMtlzyPXe/NVmsqjy3azfubcthXWMO1/8vhquYXOUQyZeYmahqtZJaYuWF0AoExsrdsxcA6+zDqdEGUHt5Ci6lI5hocgpyl70OLXWN7bhWE90XTe/POYR+ZxNbp2D38RRlbB9lgP5nlGkoNEDeK2svnY7drfOc9nXW2IQDsD54qVw+e8mtoqkUz+LoGRoBs8I+uloIw4lbpYdiaZY4rajB27xBEk4lIUUMlwVK8zCVQdYxyYxz1+JJtsqHFjZLhIZ0Bdi7g4Hfv4C2sbLensdk4vtXz7IzSic9hb6iQy8bs+kB6Jc5QazdjcMtVFYrTQW9wJal/jKSJMoGYOq398ZjhMPAa8oOuJL5kpUtsdPr2DURbnPFYcM3niB7qOjbsJvnoEIJRusNUiF5EBweAf5o8P/FhmaNwEBrkT9ODm7k8JAYMBhmaAtj0OoQkMuf6W5je0CIHB/zs3fb2BMZC8R68YwYxPCmcl64fSlVdMzqdgMj+6HPWEkIdJs0fO4KIEbNg1ANUpKcjvIug8iiT03qRFhWIt1HH8n3F2DUf/udzBffhiHcP+D98jHpum5BMfbONl745xNjeYfwlW9b1obTBiEH7WPz5h7y4x58qEcwbNw/noY93YbVpPHpJXwK8DRj0gvDR42DE1Vz9XRavpx8l0MfAf24bxa8/20tNo5WL+/fi+0NlrMssp9FqY0hcMFdeegX2lwUNQalYLQZ225KZqd+Kd0sDh7REvBrzSQE2NyUDsL+wFibMZrc1gT+uyIIVWfSPDuTG3r5c6OiIWKw2nlmaj59XETePS2RAjByltC1gGs80/YOK8mBSRDHf2McS3xDEdIALHmHt9t1oDdVMDY5z/Q80mwwpeQdB2uVyYAPIRr3fDI7mFdKXZpINlRS3BJEcEIUw5UFVNjmh0mNparGzl74MYw1NV76B8dunuOCQXEzvqFdfgkpOvh/Hg+sNDAycyx9Mz8ml1C998aTlfwpKCBTnJtGD4f4NHY/7hsAN79OUni6T2G3XeeoKfS+F+zdCr/6uY86EtqOh99MaEcmONaMMXnDt/E4v5R2R7Hrh5ZjHUboPpj3L0ISTjA4LcsTao+UM3JGJrjAKkWmyVwo85fMcu2r8WdovxnX+8r8DGrF6Iysfm0xGUQ2X/+sHdAJG3/YiH6xK47rx/fEf6BK/X0xOYVLfCOJD/Rj9wnf0CvQhxM8L8GLsZbdQtXcNIxJCuGxwDK/coPHEoj1M7hfJfZNTEAh5Eb2BJy5No6HZxojEECamRrDsoUks2VPI8IRQvj9Uxjf75ezv/jGB+Pr5Q3gfgpMn0KvRm72NyVxo2EsdvtyxPZHbW7Zxh8GXrwqDgEYyS81YRvycf+wfRkpkA3dMSOYfqzL56qidOx31WLK7iM93FmDUC45V1HHPpBRe+TaTsb3DKEGGlTK1BIoNvbnYscJtfnUjd5X+DLsGB7134gsynNhsljOYUy8Cow95RJPo/MD6Xsq2re/QF+gtithrj6fROxK/8m9Bs7OvMQKjXmC1afyp/AKSrBq3R17KkZCDXNv4CjavIAJC+/7ofhzHyuvJsCbx3O0fo9v0Kgy78aTlfwpKCBTnL9f+RybcTgWdTg5PBIgcIIfVejvyDY64NYDvVX89tes6E/BD58jJfyfDKQTOpRja4lyl1uDLfXOuYWteHb0C24T79O1/0oNigxmRGEKQj5GRqTGMTH2qwyWFEAyKlb3q2aMSCPRxXSM+1I/nrxrUuhHSlcNiuWxwNEZ9x6iyXieYe9Wg1tfBfkZum5CMxWpDCLmUhk5A316Oz/POZeDlR2zeXvbVy/kvn7ZMprTFSNBlT3L1ykkcLWskKdyP3MoGDpeY2VtgYvrAKO6YmExuZQMLNmVjtlhparHz3w3Z9I8OZEpaJO+sz6ah2ca+whoOl5pJCvejyNRImL8XfXsFku3YcnXBphyca/XlWoPoD1T3GkNowWrpFSSOA+Croxr3akbyiSLUGM3WEjs3G8Bgb6ZcCyE78iIGio8Rmp2tNcFMTI1gbWY5W8qNbGEaY0rM/DZnBBOC+xCdkEpaQDCLtudzyStref6qQUzs02bAA1Df1EJlvZzslhcyluTbFnf8LnQjSggU5y9Rg368zMn45ab2r/VGmQcITT71vEjieHimpOOOdp0R5AhRdCoEcpQTMUMZlRLFqJQTzDhvw//uHocQXTPzz9cN6XDstgnJ7V53JgInw8eoJz7Ul/yqRu6YkISvl2OEjGMyZVyIL+vzB7M3bAb/KbqCsb3DuG3qUNJzmjh6qIxbxyXx4vKDrMgoobrBytB4Ge6bNSSa/27I5rJ/rG/dYvTl2UNJjfTnP2uPscuxmF9zi50JKeFYbRp+jnt/ubuQFpudz3YUcFH/XqzLLOeA2Y/+wGs5MTzraBmtseMwAkv3lRJov5gMeyI+q45QbXcNp/7KdgF+xpHsG/BvxJ5POOI1gBcnJrM20zXZbNXBUqyann0zFhI9MJr+u6uwWO1kldXx2c6CDkKQX+1aruJAcS3JjiXl3YUSAoXiRHTWep5st7kfoysiAND/crj0BSkexxPRT46MiTt5Qr0t/t49/zO/bkQ8NY1Wfn/FwA7n4kJ9qcWfhive4O6CmtbtWH99WX+abXZuGJ3A6+lZfLxV7lMxzCEEIxNDCfEWFNc0cv/UVAJ9DFwzPA69ThAR4EVFXTM3j0vkoy15DEsI4aaxMrjz7oZszJYWvj1QSnWDletHxlNubmJVZROX480hn+FY9CvQW0wsrYyhn5/0KrLGP8unm/PQb81janhvMIM25SkK0lNJP1zOhqwQLhs8lw1zhiOEIMTP2Lqvt1MU+iTEgLc/Vw7zpqKuiR251aw/UoGmaYg237e8SpcQLN9XzIr9Jbxw7WCCfFzLv3cnPf8NUSgU7fEJknMoOsPLH27/Ui7pcQ7x2PQTj3YZEhdMiJ+RQbFBjE8Jbz2eFh3IB3fL0Myjl/TjuSUZeOl1pDm2adXpBPcP82bIsGFMTG3fo75xTCIHimv5zcz+eBt0XDbIlcgf4ci5/OHrDIx6weR+EWzLqeK9jTUs513+eeNwvHd8zsEiE6+uL2RkUgPeBh2PT0/j8x2FNFptTBg7DkbnIHxDGXB4E6sPleFj1PHkjLTWBj0+1BdTg5XkcD9yKhvwMepIDJOeRKCPkYcv7sui7fmszSxn09FKAnwMpEUH4m3Qk+9YmbZXoDdL98rcysTUcG4cm4g7UEKgUJxr9J7c0xZ0K1cMjWHm4GgMJwk53T4hiUJTI6aGZrwMrnJpYfoOIgDwqxlprc+fu7K9aA5PCGFKv0jWZpZzYZ8IAn2MzB4VT5nZws1jk6RHkvgG5hwTxxYVc6yinutGxhHm78Wg2CB25Zu4angs+MrczL9uGsHB4lpSIwOID3WFjJLC/amsa2ZMchg5lQ307RWIXtfey5zk4YmZgAAACddJREFU8H5uflsuMuil1zEySW4FG+BtYEJqOF/tLsKoFyzbV6yEQKFQnJ8IITDoT57EEELw21kDuu2eT85I44esCmY6dsobHBfM67e0GboclsK4MHikMpNXVx/h1vFyWPHdF/Ymp7KhXYI+OtiH6OCO83N+O2sAtY3W1v0m+kUFdigTE+zL1LRIbHaN2aPi2V9Yw/sbc2m22RkQE8ScMQmE+nnhY9Tz1vpjVNU3d7hGd6CEQKFQeByD44JZ9+tpxASdfILlY9P7cev4JCIDvQGYOSTmpOXbEhfiS1yIr9zICOgf3VEIAN67a2zr86uHx2G2tPDJtnwSw3yZmBrBxNQIMopqmL/2KCszSui6BV1HzSxWKBQeSVyIr5yk9yM4ReB0GRIXjJdex5jeXVtZ+J5JcihtUrhrpNDAmCCevXwAE1PDT/S2n4TyCBQKhcKNJIX7k/H8jC4Pu+3TK5D3fz6WAW08CCEE90xKASDbDTYqIVAoFAo3c6pzL6b0O8UZ8T8RFRpSKBQKD0cJgUKhUHg4bhUCIcRlQvx/e/cbI9VVh3H8+7gtDXEbbEuyIYKFWt6saS24aRvTtKCNFkyKpk0KqdoYDLERrTGaYkhM0/RNMf4JlhhpisHauGq1dV/U/pGCmmgpVJctlGC3SKIESlGLbmJoiz9f3EO4DDOw7u7Z6c55Pslm7j337t3z4yz7zL135oz2SRqWtKbJ9i9LeknSkKQtki7N2R8zMztTtiCQ1AVsAJYAvcAKSY3vL/8T0BcRVwKPAuty9cfMzJrLeUZwNTAcEfsj4g2gH1hW3yEitkbEyUk1ngNmY2Zmk0qR6cOQJd0K3BQRn03rnwKuiYimc/BKegA4HBH3Ndm2ClgF0NPT84H+/v4x9WlkZITu7u4xfe9UVWLNUGbdrrkMY6158eLFL0RE09kK3xYvH5X0SaAPuKHZ9ojYCGwE6Ovri0WLFo3p52zbto2xfu9UVWLNUGbdrrkMOWrOGQQHgTm19dmp7TSSbgTWAjdExPGM/TEzsyZy3iPYAcyXNE/SNGA5MFDfQdIC4PvAzRFxJGNfzMyshWxBEBFvAauBp4C9wE8jYo+keyXdnHb7BtAN/EzSoKSBFoczM7NMst4jiIgngCca2r5eW74x5883M7Nz8zuLzcwK5yAwMyucg8DMrHAOAjOzwjkIzMwK5yAwMyucg8DMrHAOAjOzwjkIzMwK5yAwMyucg8DMrHAOAjOzwjkIzMwK5yAwMyucg8DMrHAOAjOzwjkIzMwK5yAwMyucg8DMrHAOAjOzwjkIzMwK5yAwMyucg8DMrHAOAjOzwjkIzMwK5yAwMyucg8DMrHAOAjOzwjkIzMwK5yAwMyucg8DMrHAOAjOzwjkIzMwK5yAwMyucg8DMrHBZg0DSTZL2SRqWtKbJ9gsk/SRt3y5pbs7+mJnZmbIFgaQuYAOwBOgFVkjqbdhtJfDPiLgc+DZwf67+mJlZcznPCK4GhiNif0S8AfQDyxr2WQZsTsuPAh+WpIx9MjOzBudlPPa7gb/W1v8GXNNqn4h4S9Ix4BLgaH0nSauAVWl1RNK+MfZpZuOxC1BizVBm3a65DGOt+dJWG3IGwYSJiI3AxvEeR9LOiOibgC5NGSXWDGXW7ZrLkKPmnJeGDgJzauuzU1vTfSSdB8wA/p6xT2Zm1iBnEOwA5kuaJ2kasBwYaNhnALgjLd8KPBsRkbFPZmbWINuloXTNfzXwFNAFbIqIPZLuBXZGxADwEPCwpGHgH1RhkdO4Ly9NQSXWDGXW7ZrLMOE1y0/AzczK5ncWm5kVzkFgZla4YoLgXNNddApJByS9KGlQ0s7UdrGkZyS9nB4vanc/x0PSJklHJO2utTWtUZX1adyHJC1sX8/HrkXN90g6mMZ6UNLS2ravpZr3Sfpoe3o9PpLmSNoq6SVJeyTdldo7dqzPUnPesY6Ijv+iuln9CnAZMA3YBfS2u1+Zaj0AzGxoWwesSctrgPvb3c9x1ng9sBDYfa4agaXArwAB1wLb293/Caz5HuArTfbtTb/jFwDz0u9+V7trGEPNs4CFaflC4M+pto4d67PUnHWsSzkjGM10F52sPpXHZuDjbezLuEXEb6leZVbXqsZlwA+j8hzwLkmzJqenE6dFza0sA/oj4nhE/AUYpvo/MKVExKGI+GNa/jewl2o2go4d67PU3MqEjHUpQdBsuouz/eNOZQE8LemFNDUHQE9EHErLh4Ge9nQtq1Y1dvrYr06XQTbVLvl1XM1pZuIFwHYKGeuGmiHjWJcSBCW5LiIWUs36+nlJ19c3RnU+2dGvGS6hxuR7wHuBq4BDwDfb2508JHUDPwe+FBH/qm/r1LFuUnPWsS4lCEYz3UVHiIiD6fEI8BjVaeKrJ0+R0+OR9vUwm1Y1duzYR8SrEXEiIv4LPMipSwIdU7Ok86n+ID4SEb9IzR091s1qzj3WpQTBaKa7mPIkvVPShSeXgY8Auzl9Ko87gF+2p4dZtapxAPh0ekXJtcCx2mWFKa3h+vcnqMYaqpqXq/rgp3nAfOD5ye7feKUp6R8C9kbEt2qbOnasW9WcfazbfZd8Eu/GL6W6A/8KsLbd/clU42VUryDYBew5WSfV1N5bgJeBXwMXt7uv46zzx1Snx29SXRNd2apGqleQbEjj/iLQ1+7+T2DND6eahtIfhFm1/demmvcBS9rd/zHWfB3VZZ8hYDB9Le3ksT5LzVnH2lNMmJkVrpRLQ2Zm1oKDwMyscA4CM7PCOQjMzArnIDAzK5yDwCyRdKI2u+PgRM5SK2lufeZQs7eTbB9VaTYF/Scirmp3J8wmm88IzM4hfcbDuvQ5D89Lujy1z5X0bJoIbIuk96T2HkmPSdqVvj6YDtUl6cE0z/zTkqan/b+Y5p8fktTfpjKtYA4Cs1OmN1wauq227VhEXAE8AHwntX0X2BwRVwKPAOtT+3rgNxHxfqrPENiT2ucDGyLifcDrwC2pfQ2wIB3nc7mKM2vF7yw2SySNRER3k/YDwIciYn+aEOxwRFwi6SjVW/3fTO2HImKmpNeA2RFxvHaMucAzETE/rd8NnB8R90l6EhgBHgcej4iRzKWancZnBGajEy2W/x/Ha8snOHWP7mNUc+QsBHZI8r07m1QOArPRua32+Ie0/HuqmWwBbgd+l5a3AHcCSOqSNKPVQSW9A5gTEVuBu4EZwBlnJWY5+ZmH2SnTJQ3W1p+MiJMvIb1I0hDVs/oVqe0LwA8kfRV4DfhMar8L2ChpJdUz/zupZg5tpgv4UQoLAesj4vUJq8hsFHyPwOwc0j2Cvog42u6+mOXgS0NmZoXzGYGZWeF8RmBmVjgHgZlZ4RwEZmaFcxCYmRXOQWBmVrj/ATj4by9VFZI8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bQcLoc0j20Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ff2853-6070-4ab5-e267-11a77cdddfdd"
      },
      "source": [
        "results = model.evaluate([x_test, x_angle_test], y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2742 - accuracy: 0.8986\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}