{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQC+aiIpwIZDjwZL1lexiw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eikeschuett/IcebergShipDetection/blob/main/CNN_training_iceberg_ship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp_u7zwvt_jw"
      },
      "source": [
        "import numpy as np # linear algebra\r\n",
        "np.random.seed(666)\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from subprocess import check_output\r\n",
        "from matplotlib import pyplot\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Lambda\r\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.layers.merge import Concatenate\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.optimizers import Adam, SGD\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from scipy.ndimage.filters import uniform_filter\r\n",
        "from scipy.ndimage.measurements import variance"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "7nYBzmT4uDBU",
        "outputId": "72987491-ad41-4883-f3ec-841617a7b153"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive')\r\n",
        "data = pd.read_json('/content/drive/MyDrive/Iceberg_Ship_Classification/train.json')\r\n",
        "\r\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>band_1</th>\n",
              "      <th>band_2</th>\n",
              "      <th>inc_angle</th>\n",
              "      <th>is_iceberg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dfd5f913</td>\n",
              "      <td>[-27.878360999999998, -27.15416, -28.668615, -...</td>\n",
              "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
              "      <td>43.9239</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e25388fd</td>\n",
              "      <td>[-12.242375, -14.920304999999999, -14.920363, ...</td>\n",
              "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
              "      <td>38.1562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>58b2aaa0</td>\n",
              "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
              "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
              "      <td>45.2859</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4cfc3a18</td>\n",
              "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
              "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
              "      <td>43.8306</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>271f93f4</td>\n",
              "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
              "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
              "      <td>35.6256</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... is_iceberg\n",
              "0  dfd5f913  ...          0\n",
              "1  e25388fd  ...          0\n",
              "2  58b2aaa0  ...          1\n",
              "3  4cfc3a18  ...          0\n",
              "4  271f93f4  ...          0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LbOp4V82ZMg"
      },
      "source": [
        "Delete all observations without an inclination angle (133 in total) instead of replacing it with some random values..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiyDkJP5gPwu",
        "outputId": "18ee0295-41b8-49fb-9cb3-a955042bcd7b"
      },
      "source": [
        "print(len(data))\r\n",
        "data.inc_angle = data.inc_angle.replace('na', np.nan)\r\n",
        "\r\n",
        "#data.inc_angle = data.inc_angle.astype(float).fillna(0.0)\r\n",
        "data = data.dropna(axis=0, how='any')\r\n",
        "print(len(data))\r\n",
        "print(data.inc_angle.min())\r\n",
        "print(data.inc_angle.max())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1604\n",
            "1471\n",
            "24.7546\n",
            "45.9375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzAKZG0RuZ2b"
      },
      "source": [
        "def lee_filter(img, size):\r\n",
        "    # From here: https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\r\n",
        "    img_mean = uniform_filter(img, (size, size))\r\n",
        "    img_sqr_mean = uniform_filter(img**2, (size, size))\r\n",
        "    img_variance = img_sqr_mean - img_mean**2\r\n",
        "\r\n",
        "    overall_variance = variance(img)\r\n",
        "\r\n",
        "    img_weights = img_variance / (img_variance + overall_variance)\r\n",
        "    img_output = img_mean + img_weights * (img - img_mean)\r\n",
        "    return img_output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqww4ARyuabj"
      },
      "source": [
        "def prepare_data(data):\r\n",
        "  x_angle = np.array(data[\"inc_angle\"])\r\n",
        "\r\n",
        "  # Get the labels (y-values)\r\n",
        "  labels = np.array(data[\"is_iceberg\"])\r\n",
        "\r\n",
        "  # Create empty list for the images\r\n",
        "  imgs = []\r\n",
        "  for i, row in data.iterrows():\r\n",
        "      # Reshape list to image\r\n",
        "      hh  = np.reshape(row[\"band_1\"], (75, 75))\r\n",
        "      hv  = np.reshape(row[\"band_2\"], (75, 75))\r\n",
        "      b3  = hh + hv\r\n",
        "\r\n",
        "      hh = lee_filter(hh, 20)\r\n",
        "      hv = lee_filter(hv, 20)\r\n",
        "      b3 = lee_filter(b3, 20)      \r\n",
        "        \r\n",
        "      # Rescale images between 0 and 1 for faster convergence rate\r\n",
        "      hh = (hh - hh.min())/(hh.max()-hh.min())\r\n",
        "      hv = (hv - hv.min())/(hv.max()-hv.min())\r\n",
        "      b3 = (b3 - b3.min())/(b3.max()-b3.min())      \r\n",
        "\r\n",
        "      # Stack the bands and append them to imgs\r\n",
        "      imgs.append(np.dstack((hh, hv, b3)))\r\n",
        "      \r\n",
        "  # Split dataset into training (70%)  and validation (30 %)\r\n",
        "  x_train, x_val, x_angle_train, x_angle_val, y_train, y_val = train_test_split(imgs, \r\n",
        "                                                    x_angle,\r\n",
        "                                                    labels, \r\n",
        "                                                    test_size=0.3, \r\n",
        "                                                    random_state=0)\r\n",
        "  # Then split validation dataset into validation (20 %) and testing (10 %)\r\n",
        "  x_val, x_test, x_angle_val, x_angle_test, y_val, y_test = train_test_split(x_val,\r\n",
        "                                                  x_angle_val,\r\n",
        "                                                  y_val,\r\n",
        "                                                  test_size=(1/3),\r\n",
        "                                                  random_state=0)\r\n",
        "\r\n",
        "  x_train = np.array(x_train)\r\n",
        "  x_test = np.array(x_test)\r\n",
        "  x_val = np.array(x_val)\r\n",
        "  x_angle_test = np.array(x_angle_test)\r\n",
        "  x_angle_train = np.array(x_angle_train)\r\n",
        "  x_angle_val = np.array(x_angle_val)\r\n",
        "  return x_train, x_val, x_test, x_angle_train, x_angle_val, x_angle_test, y_train, y_val, y_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28CxgXc60t2u",
        "outputId": "8627ba62-6377-4537-cc28-83f4e1bf883e"
      },
      "source": [
        "x_train, x_val, x_test, x_angle_train, x_angle_val, x_angle_test, y_train, y_val, y_test = prepare_data(data)\r\n",
        "print(\"Number of samples for training: \" + str(len(x_train)) + \" (\" + str(round(len(x_train)/len(data), 4)*100) + \" %)\")\r\n",
        "print(\"Number of samples for validation: \" + str(len(x_val)) + \" (\" + str(round(len(x_val)/len(data), 4)*100) + \" %)\")\r\n",
        "print(\"Number of samples for testing: \" + str(len(x_test)) + \" (\" + str(round(len(x_test)/len(data), 4)*100) + \" %)\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples for training: 1029 (69.95 %)\n",
            "Number of samples for validation: 294 (19.99 %)\n",
            "Number of samples for testing: 148 (10.059999999999999 %)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oezdQAC3Zx_"
      },
      "source": [
        "Create two data generators for both images and the inclination angle and combine them. I have the code from https://www.kaggle.com/sinkie/keras-data-augmentation-with-multiple-inputs, but still don't understand what this is doing exactly..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-_w43W5M60A"
      },
      "source": [
        "# From here: https://www.kaggle.com/sinkie/keras-data-augmentation-with-multiple-inputs\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "gen = ImageDataGenerator(\r\n",
        "      rotation_range = 45,\r\n",
        "      width_shift_range = 0.15,\r\n",
        "      height_shift_range = 0.15,\r\n",
        "      shear_range = 0.15,\r\n",
        "      zoom_range = 0.15,\r\n",
        "      horizontal_flip = True,\r\n",
        "      vertical_flip = True,\r\n",
        "      fill_mode = 'nearest')\r\n",
        "\r\n",
        "# Here is the function that merges our two generators\r\n",
        "# We use the exact same generator with the same random seed for both the y and angle arrays\r\n",
        "def gen_flow_for_two_inputs(X1, X2, y):\r\n",
        "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=666)\r\n",
        "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=666)\r\n",
        "    while True:\r\n",
        "            X1i = genX1.next()\r\n",
        "            X2i = genX2.next()\r\n",
        "            #Assert arrays are equal - this was for peace of mind, but slows down training\r\n",
        "            #np.testing.assert_array_equal(X1i[0],X2i[0])\r\n",
        "            yield [X1i[0], X2i[1]], X1i[1]\r\n",
        "\r\n",
        "# Finally create generator\r\n",
        "gen_flow = gen_flow_for_two_inputs(x_train, x_angle_train, y_train)\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b32oC96X1c1M"
      },
      "source": [
        "# train_generator, val_generator = DataGenerators(x_train, x_val, y_train, y_val)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVC3fO7Hw5Uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3c1df1-1731-4e05-ca99-aea056c063d3"
      },
      "source": [
        "def create_model(optimizer):\r\n",
        "  ac_fct      = \"relu\"\r\n",
        "  #momentum    = 0\r\n",
        "\r\n",
        "  input_img   = Input(shape=(75, 75 ,3), name=\"X_img\")\r\n",
        "  input_angle = Input(shape=[1], name=\"angle\")\r\n",
        "\r\n",
        "  #cnn = BatchNormalization()(input_img)\r\n",
        "  cnn = Conv2D(16, kernel_size=(3,3), activation = \"relu\")(input_img)\r\n",
        "  #cnn = Conv2D(16, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  cnn = MaxPooling2D((2,2))(cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)\r\n",
        "\r\n",
        "  cnn = Conv2D(32, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  #cnn = Conv2D(32, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  cnn = MaxPooling2D((2,2)) (cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)\r\n",
        "\r\n",
        "  cnn = Conv2D(64, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  #cnn = Conv2D(64, kernel_size=(3,3), activation = \"relu\") (cnn)\r\n",
        "  cnn = MaxPooling2D((2,2)) (cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)  \r\n",
        "\r\n",
        "  cnn = Conv2D(128, kernel_size=(3,3), activation = \"relu\")(cnn)\r\n",
        "  cnn = Conv2D(128, kernel_size=(3,3), activation = \"relu\") (cnn)\r\n",
        "  cnn = MaxPooling2D((2,2)) (cnn)\r\n",
        "  cnn = Dropout(0.1) (cnn)  \r\n",
        "  \r\n",
        "\r\n",
        "  cnn = GlobalMaxPooling2D() (cnn)\r\n",
        "\r\n",
        "  #angle = BatchNormalization(momentum=0)(input_angle)\r\n",
        "  angle = Lambda(lambda x: (x - 25)/(45-25))(input_angle)\r\n",
        "  \r\n",
        "  concat = (Concatenate()([cnn, angle]))\r\n",
        "\r\n",
        "  dense = Dense(32, activation=\"relu\") (concat)\r\n",
        "  # dense = BatchNormalization() (dense)\r\n",
        "  # dense = Dropout(0.2)(dense)\r\n",
        "  \r\n",
        "  #dense = Dense(128, activation=\"relu\") (dense)\r\n",
        "  #dense = BatchNormalization() (dense)\r\n",
        "  #dense = Dropout(0.2)(dense)\r\n",
        "\r\n",
        "  #dense = Dense(128, activation=\"relu\") (dense)\r\n",
        "  #dense = BatchNormalization() (dense)\r\n",
        "  #dense = Dropout(0.2)(dense)\r\n",
        "\r\n",
        "  output = Dense(1, activation=\"sigmoid\")(dense)\r\n",
        "\r\n",
        "  model = Model([input_img, input_angle], output)\r\n",
        "  #optimizer = Adam(lr=0.1, epsilon=1e-08, decay=0.0)\r\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\r\n",
        "  return model\r\n",
        "\r\n",
        "epochs = 250\r\n",
        "# learning_rate = 0.1\r\n",
        "# decay_rate = learning_rate / epochs\r\n",
        "# momentum = 0.8\r\n",
        "# sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\r\n",
        "\r\n",
        "# from keras.optimizers import Adadelta\r\n",
        "model = create_model(optimizer = Adam())\r\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "X_img (InputLayer)              [(None, 75, 75, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 73, 73, 16)   448         X_img[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 36, 36, 16)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 36, 36, 16)   0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 34, 34, 32)   4640        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 17, 17, 32)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 17, 17, 32)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 15, 15, 64)   18496       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 64)     0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 64)     0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 5, 5, 128)    73856       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 3, 3, 128)    147584      conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 128)    0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1, 1, 128)    0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "angle (InputLayer)              [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 128)          0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 1)            0           angle[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 129)          0           global_max_pooling2d[0][0]       \n",
            "                                                                 lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           4160        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 249,217\n",
            "Trainable params: 249,217\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpDHGNPh1KSV"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJbwtdGeNO02",
        "outputId": "aa9b647d-445f-4fa2-92d7-b7254571f63e"
      },
      "source": [
        "history = model.fit(gen_flow, validation_data=([x_val, x_angle_val], y_val),\r\n",
        "                    steps_per_epoch=len(x_train) / batch_size, epochs=epochs)\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "32/32 [==============================] - 6s 118ms/step - loss: 0.6983 - accuracy: 0.5280 - val_loss: 0.6857 - val_accuracy: 0.5068\n",
            "Epoch 2/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.6798 - accuracy: 0.5542 - val_loss: 0.6170 - val_accuracy: 0.6156\n",
            "Epoch 3/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.6371 - accuracy: 0.6734 - val_loss: 0.5831 - val_accuracy: 0.6531\n",
            "Epoch 4/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.5898 - accuracy: 0.6893 - val_loss: 0.5526 - val_accuracy: 0.7279\n",
            "Epoch 5/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.5751 - accuracy: 0.7036 - val_loss: 0.5395 - val_accuracy: 0.7109\n",
            "Epoch 6/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.5629 - accuracy: 0.7114 - val_loss: 0.5143 - val_accuracy: 0.7415\n",
            "Epoch 7/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.5782 - accuracy: 0.6821 - val_loss: 0.5257 - val_accuracy: 0.7415\n",
            "Epoch 8/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.5385 - accuracy: 0.7434 - val_loss: 0.5176 - val_accuracy: 0.7517\n",
            "Epoch 9/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.5283 - accuracy: 0.7306 - val_loss: 0.5106 - val_accuracy: 0.7483\n",
            "Epoch 10/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.4914 - accuracy: 0.7671 - val_loss: 0.5318 - val_accuracy: 0.7381\n",
            "Epoch 11/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.4716 - accuracy: 0.7797 - val_loss: 0.4635 - val_accuracy: 0.7857\n",
            "Epoch 12/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.5012 - accuracy: 0.7482 - val_loss: 0.4159 - val_accuracy: 0.7959\n",
            "Epoch 13/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.4967 - accuracy: 0.7588 - val_loss: 0.4894 - val_accuracy: 0.7551\n",
            "Epoch 14/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.4628 - accuracy: 0.7918 - val_loss: 0.3983 - val_accuracy: 0.8197\n",
            "Epoch 15/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.4528 - accuracy: 0.7787 - val_loss: 0.4120 - val_accuracy: 0.8095\n",
            "Epoch 16/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.4447 - accuracy: 0.7822 - val_loss: 0.4089 - val_accuracy: 0.7959\n",
            "Epoch 17/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.4193 - accuracy: 0.8045 - val_loss: 0.3591 - val_accuracy: 0.8435\n",
            "Epoch 18/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.4347 - accuracy: 0.7771 - val_loss: 0.4570 - val_accuracy: 0.7755\n",
            "Epoch 19/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.4478 - accuracy: 0.7869 - val_loss: 0.3764 - val_accuracy: 0.8537\n",
            "Epoch 20/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.4179 - accuracy: 0.8044 - val_loss: 0.3541 - val_accuracy: 0.8469\n",
            "Epoch 21/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.4162 - accuracy: 0.8145 - val_loss: 0.3439 - val_accuracy: 0.8673\n",
            "Epoch 22/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3883 - accuracy: 0.8154 - val_loss: 0.3470 - val_accuracy: 0.8537\n",
            "Epoch 23/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3707 - accuracy: 0.8283 - val_loss: 0.4233 - val_accuracy: 0.7925\n",
            "Epoch 24/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.4094 - accuracy: 0.7927 - val_loss: 0.4257 - val_accuracy: 0.8129\n",
            "Epoch 25/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.4335 - accuracy: 0.7918 - val_loss: 0.3466 - val_accuracy: 0.8503\n",
            "Epoch 26/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3743 - accuracy: 0.8361 - val_loss: 0.3888 - val_accuracy: 0.8265\n",
            "Epoch 27/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.4100 - accuracy: 0.7936 - val_loss: 0.3334 - val_accuracy: 0.8673\n",
            "Epoch 28/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.4020 - accuracy: 0.8222 - val_loss: 0.3735 - val_accuracy: 0.8401\n",
            "Epoch 29/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3549 - accuracy: 0.8375 - val_loss: 0.3632 - val_accuracy: 0.8503\n",
            "Epoch 30/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3779 - accuracy: 0.8288 - val_loss: 0.3875 - val_accuracy: 0.8333\n",
            "Epoch 31/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.4355 - accuracy: 0.7796 - val_loss: 0.3633 - val_accuracy: 0.8503\n",
            "Epoch 32/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.4218 - accuracy: 0.7963 - val_loss: 0.3408 - val_accuracy: 0.8605\n",
            "Epoch 33/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3975 - accuracy: 0.8141 - val_loss: 0.3501 - val_accuracy: 0.8639\n",
            "Epoch 34/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3786 - accuracy: 0.8192 - val_loss: 0.3387 - val_accuracy: 0.8503\n",
            "Epoch 35/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3492 - accuracy: 0.8343 - val_loss: 0.3357 - val_accuracy: 0.8639\n",
            "Epoch 36/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3781 - accuracy: 0.8206 - val_loss: 0.3955 - val_accuracy: 0.8367\n",
            "Epoch 37/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3887 - accuracy: 0.8171 - val_loss: 0.3409 - val_accuracy: 0.8707\n",
            "Epoch 38/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3794 - accuracy: 0.8236 - val_loss: 0.3391 - val_accuracy: 0.8673\n",
            "Epoch 39/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3437 - accuracy: 0.8429 - val_loss: 0.3335 - val_accuracy: 0.8571\n",
            "Epoch 40/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3877 - accuracy: 0.8315 - val_loss: 0.3179 - val_accuracy: 0.8571\n",
            "Epoch 41/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3949 - accuracy: 0.8155 - val_loss: 0.3565 - val_accuracy: 0.8197\n",
            "Epoch 42/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3567 - accuracy: 0.8418 - val_loss: 0.3676 - val_accuracy: 0.8231\n",
            "Epoch 43/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3816 - accuracy: 0.8159 - val_loss: 0.3252 - val_accuracy: 0.8605\n",
            "Epoch 44/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3702 - accuracy: 0.8290 - val_loss: 0.3510 - val_accuracy: 0.8469\n",
            "Epoch 45/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3669 - accuracy: 0.8242 - val_loss: 0.3342 - val_accuracy: 0.8435\n",
            "Epoch 46/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3666 - accuracy: 0.8207 - val_loss: 0.3794 - val_accuracy: 0.7687\n",
            "Epoch 47/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3851 - accuracy: 0.8136 - val_loss: 0.3237 - val_accuracy: 0.8639\n",
            "Epoch 48/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3621 - accuracy: 0.8307 - val_loss: 0.3631 - val_accuracy: 0.8401\n",
            "Epoch 49/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3675 - accuracy: 0.8289 - val_loss: 0.3217 - val_accuracy: 0.8741\n",
            "Epoch 50/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3924 - accuracy: 0.7946 - val_loss: 0.3231 - val_accuracy: 0.8503\n",
            "Epoch 51/250\n",
            "32/32 [==============================] - 3s 87ms/step - loss: 0.3514 - accuracy: 0.8359 - val_loss: 0.3239 - val_accuracy: 0.8503\n",
            "Epoch 52/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3369 - accuracy: 0.8418 - val_loss: 0.3069 - val_accuracy: 0.8605\n",
            "Epoch 53/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3391 - accuracy: 0.8294 - val_loss: 0.3125 - val_accuracy: 0.8605\n",
            "Epoch 54/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3568 - accuracy: 0.8375 - val_loss: 0.3220 - val_accuracy: 0.8707\n",
            "Epoch 55/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3499 - accuracy: 0.8468 - val_loss: 0.3244 - val_accuracy: 0.8537\n",
            "Epoch 56/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3640 - accuracy: 0.8270 - val_loss: 0.3219 - val_accuracy: 0.8503\n",
            "Epoch 57/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3683 - accuracy: 0.8193 - val_loss: 0.3166 - val_accuracy: 0.8639\n",
            "Epoch 58/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3534 - accuracy: 0.8343 - val_loss: 0.3073 - val_accuracy: 0.8639\n",
            "Epoch 59/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3669 - accuracy: 0.8243 - val_loss: 0.3348 - val_accuracy: 0.8605\n",
            "Epoch 60/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3801 - accuracy: 0.8279 - val_loss: 0.3380 - val_accuracy: 0.8469\n",
            "Epoch 61/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3720 - accuracy: 0.8240 - val_loss: 0.3126 - val_accuracy: 0.8673\n",
            "Epoch 62/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3444 - accuracy: 0.8264 - val_loss: 0.3409 - val_accuracy: 0.8469\n",
            "Epoch 63/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3318 - accuracy: 0.8419 - val_loss: 0.3354 - val_accuracy: 0.8605\n",
            "Epoch 64/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3733 - accuracy: 0.8165 - val_loss: 0.3295 - val_accuracy: 0.8571\n",
            "Epoch 65/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3459 - accuracy: 0.8189 - val_loss: 0.3314 - val_accuracy: 0.8469\n",
            "Epoch 66/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3508 - accuracy: 0.8315 - val_loss: 0.3165 - val_accuracy: 0.8639\n",
            "Epoch 67/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3179 - accuracy: 0.8475 - val_loss: 0.3239 - val_accuracy: 0.8639\n",
            "Epoch 68/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3661 - accuracy: 0.8229 - val_loss: 0.3124 - val_accuracy: 0.8673\n",
            "Epoch 69/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3832 - accuracy: 0.8191 - val_loss: 0.3199 - val_accuracy: 0.8639\n",
            "Epoch 70/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3591 - accuracy: 0.8050 - val_loss: 0.3557 - val_accuracy: 0.8367\n",
            "Epoch 71/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.4009 - accuracy: 0.8103 - val_loss: 0.3220 - val_accuracy: 0.8707\n",
            "Epoch 72/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3511 - accuracy: 0.8562 - val_loss: 0.3685 - val_accuracy: 0.8299\n",
            "Epoch 73/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3521 - accuracy: 0.8325 - val_loss: 0.3304 - val_accuracy: 0.8673\n",
            "Epoch 74/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3492 - accuracy: 0.8415 - val_loss: 0.3279 - val_accuracy: 0.8605\n",
            "Epoch 75/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3547 - accuracy: 0.8395 - val_loss: 0.3193 - val_accuracy: 0.8639\n",
            "Epoch 76/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3521 - accuracy: 0.8316 - val_loss: 0.3193 - val_accuracy: 0.8639\n",
            "Epoch 77/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3555 - accuracy: 0.8294 - val_loss: 0.3170 - val_accuracy: 0.8605\n",
            "Epoch 78/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3350 - accuracy: 0.8417 - val_loss: 0.3971 - val_accuracy: 0.7891\n",
            "Epoch 79/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3385 - accuracy: 0.8364 - val_loss: 0.3384 - val_accuracy: 0.8639\n",
            "Epoch 80/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3855 - accuracy: 0.8309 - val_loss: 0.3115 - val_accuracy: 0.8707\n",
            "Epoch 81/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3243 - accuracy: 0.8460 - val_loss: 0.3053 - val_accuracy: 0.8639\n",
            "Epoch 82/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3283 - accuracy: 0.8260 - val_loss: 0.2979 - val_accuracy: 0.8605\n",
            "Epoch 83/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3805 - accuracy: 0.8177 - val_loss: 0.3074 - val_accuracy: 0.8741\n",
            "Epoch 84/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3163 - accuracy: 0.8286 - val_loss: 0.3226 - val_accuracy: 0.8707\n",
            "Epoch 85/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3238 - accuracy: 0.8527 - val_loss: 0.3124 - val_accuracy: 0.8673\n",
            "Epoch 86/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3224 - accuracy: 0.8464 - val_loss: 0.3381 - val_accuracy: 0.8503\n",
            "Epoch 87/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3688 - accuracy: 0.8389 - val_loss: 0.3134 - val_accuracy: 0.8741\n",
            "Epoch 88/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3559 - accuracy: 0.8282 - val_loss: 0.3354 - val_accuracy: 0.8537\n",
            "Epoch 89/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3203 - accuracy: 0.8505 - val_loss: 0.3086 - val_accuracy: 0.8707\n",
            "Epoch 90/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3354 - accuracy: 0.8554 - val_loss: 0.3179 - val_accuracy: 0.8707\n",
            "Epoch 91/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3142 - accuracy: 0.8486 - val_loss: 0.3091 - val_accuracy: 0.8776\n",
            "Epoch 92/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.2937 - accuracy: 0.8673 - val_loss: 0.3295 - val_accuracy: 0.8469\n",
            "Epoch 93/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3344 - accuracy: 0.8450 - val_loss: 0.3474 - val_accuracy: 0.8333\n",
            "Epoch 94/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3163 - accuracy: 0.8531 - val_loss: 0.3086 - val_accuracy: 0.8741\n",
            "Epoch 95/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3402 - accuracy: 0.8441 - val_loss: 0.3101 - val_accuracy: 0.8707\n",
            "Epoch 96/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3371 - accuracy: 0.8468 - val_loss: 0.2952 - val_accuracy: 0.8810\n",
            "Epoch 97/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3419 - accuracy: 0.8569 - val_loss: 0.3010 - val_accuracy: 0.8776\n",
            "Epoch 98/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3037 - accuracy: 0.8599 - val_loss: 0.3320 - val_accuracy: 0.8537\n",
            "Epoch 99/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3154 - accuracy: 0.8653 - val_loss: 0.3152 - val_accuracy: 0.8844\n",
            "Epoch 100/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3299 - accuracy: 0.8405 - val_loss: 0.3425 - val_accuracy: 0.8537\n",
            "Epoch 101/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3222 - accuracy: 0.8419 - val_loss: 0.2829 - val_accuracy: 0.8810\n",
            "Epoch 102/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3518 - accuracy: 0.8389 - val_loss: 0.3040 - val_accuracy: 0.8776\n",
            "Epoch 103/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3393 - accuracy: 0.8523 - val_loss: 0.3067 - val_accuracy: 0.8571\n",
            "Epoch 104/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3653 - accuracy: 0.8380 - val_loss: 0.3109 - val_accuracy: 0.8776\n",
            "Epoch 105/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3620 - accuracy: 0.8324 - val_loss: 0.3076 - val_accuracy: 0.8810\n",
            "Epoch 106/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3329 - accuracy: 0.8505 - val_loss: 0.2988 - val_accuracy: 0.8639\n",
            "Epoch 107/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3174 - accuracy: 0.8649 - val_loss: 0.3315 - val_accuracy: 0.8707\n",
            "Epoch 108/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3456 - accuracy: 0.8420 - val_loss: 0.2984 - val_accuracy: 0.8673\n",
            "Epoch 109/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3150 - accuracy: 0.8591 - val_loss: 0.3020 - val_accuracy: 0.8741\n",
            "Epoch 110/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3092 - accuracy: 0.8514 - val_loss: 0.3235 - val_accuracy: 0.8367\n",
            "Epoch 111/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3456 - accuracy: 0.8400 - val_loss: 0.3027 - val_accuracy: 0.8673\n",
            "Epoch 112/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3404 - accuracy: 0.8305 - val_loss: 0.3074 - val_accuracy: 0.8605\n",
            "Epoch 113/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3394 - accuracy: 0.8322 - val_loss: 0.2955 - val_accuracy: 0.8673\n",
            "Epoch 114/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3410 - accuracy: 0.8449 - val_loss: 0.3010 - val_accuracy: 0.8639\n",
            "Epoch 115/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3043 - accuracy: 0.8628 - val_loss: 0.3408 - val_accuracy: 0.8571\n",
            "Epoch 116/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3711 - accuracy: 0.8261 - val_loss: 0.2906 - val_accuracy: 0.8844\n",
            "Epoch 117/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3434 - accuracy: 0.8360 - val_loss: 0.3077 - val_accuracy: 0.8673\n",
            "Epoch 118/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3117 - accuracy: 0.8501 - val_loss: 0.3502 - val_accuracy: 0.8197\n",
            "Epoch 119/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3945 - accuracy: 0.8216 - val_loss: 0.3300 - val_accuracy: 0.8571\n",
            "Epoch 120/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3311 - accuracy: 0.8442 - val_loss: 0.2905 - val_accuracy: 0.8673\n",
            "Epoch 121/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2874 - accuracy: 0.8555 - val_loss: 0.2935 - val_accuracy: 0.8844\n",
            "Epoch 122/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3449 - accuracy: 0.8373 - val_loss: 0.3065 - val_accuracy: 0.8776\n",
            "Epoch 123/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2868 - accuracy: 0.8722 - val_loss: 0.3130 - val_accuracy: 0.8810\n",
            "Epoch 124/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2811 - accuracy: 0.8721 - val_loss: 0.3401 - val_accuracy: 0.8707\n",
            "Epoch 125/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3069 - accuracy: 0.8597 - val_loss: 0.3080 - val_accuracy: 0.8741\n",
            "Epoch 126/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3213 - accuracy: 0.8468 - val_loss: 0.2976 - val_accuracy: 0.8673\n",
            "Epoch 127/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3024 - accuracy: 0.8572 - val_loss: 0.3181 - val_accuracy: 0.8707\n",
            "Epoch 128/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2669 - accuracy: 0.8866 - val_loss: 0.2983 - val_accuracy: 0.8673\n",
            "Epoch 129/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2962 - accuracy: 0.8831 - val_loss: 0.3002 - val_accuracy: 0.8810\n",
            "Epoch 130/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3016 - accuracy: 0.8637 - val_loss: 0.3448 - val_accuracy: 0.8537\n",
            "Epoch 131/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2995 - accuracy: 0.8541 - val_loss: 0.3279 - val_accuracy: 0.8707\n",
            "Epoch 132/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3398 - accuracy: 0.8403 - val_loss: 0.3000 - val_accuracy: 0.8776\n",
            "Epoch 133/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.2842 - accuracy: 0.8550 - val_loss: 0.2842 - val_accuracy: 0.8776\n",
            "Epoch 134/250\n",
            "32/32 [==============================] - 3s 89ms/step - loss: 0.3041 - accuracy: 0.8682 - val_loss: 0.3122 - val_accuracy: 0.8878\n",
            "Epoch 135/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3445 - accuracy: 0.8521 - val_loss: 0.3003 - val_accuracy: 0.8844\n",
            "Epoch 136/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3091 - accuracy: 0.8594 - val_loss: 0.3109 - val_accuracy: 0.8810\n",
            "Epoch 137/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3212 - accuracy: 0.8469 - val_loss: 0.3108 - val_accuracy: 0.8673\n",
            "Epoch 138/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2923 - accuracy: 0.8705 - val_loss: 0.3321 - val_accuracy: 0.8639\n",
            "Epoch 139/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3132 - accuracy: 0.8667 - val_loss: 0.3239 - val_accuracy: 0.8537\n",
            "Epoch 140/250\n",
            "32/32 [==============================] - 3s 88ms/step - loss: 0.3091 - accuracy: 0.8628 - val_loss: 0.2968 - val_accuracy: 0.8946\n",
            "Epoch 141/250\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 0.3047 - accuracy: 0.8715 - val_loss: 0.3025 - val_accuracy: 0.8878\n",
            "Epoch 142/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2626 - accuracy: 0.8848 - val_loss: 0.3085 - val_accuracy: 0.8844\n",
            "Epoch 143/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3236 - accuracy: 0.8468 - val_loss: 0.3000 - val_accuracy: 0.8878\n",
            "Epoch 144/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2934 - accuracy: 0.8646 - val_loss: 0.3042 - val_accuracy: 0.8707\n",
            "Epoch 145/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3464 - accuracy: 0.8285 - val_loss: 0.2996 - val_accuracy: 0.8844\n",
            "Epoch 146/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3056 - accuracy: 0.8544 - val_loss: 0.2869 - val_accuracy: 0.8912\n",
            "Epoch 147/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3020 - accuracy: 0.8535 - val_loss: 0.3149 - val_accuracy: 0.8776\n",
            "Epoch 148/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2982 - accuracy: 0.8660 - val_loss: 0.2855 - val_accuracy: 0.8776\n",
            "Epoch 149/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3224 - accuracy: 0.8678 - val_loss: 0.2764 - val_accuracy: 0.8878\n",
            "Epoch 150/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2773 - accuracy: 0.8734 - val_loss: 0.3274 - val_accuracy: 0.8844\n",
            "Epoch 151/250\n",
            "32/32 [==============================] - 3s 100ms/step - loss: 0.3076 - accuracy: 0.8713 - val_loss: 0.2999 - val_accuracy: 0.8776\n",
            "Epoch 152/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3182 - accuracy: 0.8590 - val_loss: 0.2895 - val_accuracy: 0.8810\n",
            "Epoch 153/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3485 - accuracy: 0.8447 - val_loss: 0.2733 - val_accuracy: 0.8878\n",
            "Epoch 154/250\n",
            "32/32 [==============================] - 3s 100ms/step - loss: 0.3133 - accuracy: 0.8436 - val_loss: 0.3039 - val_accuracy: 0.8810\n",
            "Epoch 155/250\n",
            "32/32 [==============================] - 3s 101ms/step - loss: 0.3163 - accuracy: 0.8673 - val_loss: 0.2974 - val_accuracy: 0.8673\n",
            "Epoch 156/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3078 - accuracy: 0.8644 - val_loss: 0.2792 - val_accuracy: 0.8878\n",
            "Epoch 157/250\n",
            "32/32 [==============================] - 3s 100ms/step - loss: 0.3016 - accuracy: 0.8636 - val_loss: 0.2927 - val_accuracy: 0.8844\n",
            "Epoch 158/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3185 - accuracy: 0.8607 - val_loss: 0.2848 - val_accuracy: 0.8878\n",
            "Epoch 159/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3020 - accuracy: 0.8514 - val_loss: 0.2883 - val_accuracy: 0.8980\n",
            "Epoch 160/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2703 - accuracy: 0.8790 - val_loss: 0.3138 - val_accuracy: 0.8469\n",
            "Epoch 161/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3154 - accuracy: 0.8341 - val_loss: 0.2771 - val_accuracy: 0.8878\n",
            "Epoch 162/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2835 - accuracy: 0.8622 - val_loss: 0.2889 - val_accuracy: 0.8912\n",
            "Epoch 163/250\n",
            "32/32 [==============================] - 3s 102ms/step - loss: 0.2849 - accuracy: 0.8777 - val_loss: 0.3043 - val_accuracy: 0.8844\n",
            "Epoch 164/250\n",
            "32/32 [==============================] - 3s 102ms/step - loss: 0.2873 - accuracy: 0.8556 - val_loss: 0.3389 - val_accuracy: 0.8605\n",
            "Epoch 165/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3196 - accuracy: 0.8362 - val_loss: 0.2913 - val_accuracy: 0.8776\n",
            "Epoch 166/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2777 - accuracy: 0.8787 - val_loss: 0.3005 - val_accuracy: 0.8673\n",
            "Epoch 167/250\n",
            "32/32 [==============================] - 4s 111ms/step - loss: 0.3157 - accuracy: 0.8766 - val_loss: 0.3295 - val_accuracy: 0.8776\n",
            "Epoch 168/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2926 - accuracy: 0.8560 - val_loss: 0.2867 - val_accuracy: 0.8912\n",
            "Epoch 169/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2819 - accuracy: 0.8774 - val_loss: 0.2939 - val_accuracy: 0.8707\n",
            "Epoch 170/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3045 - accuracy: 0.8470 - val_loss: 0.2886 - val_accuracy: 0.8912\n",
            "Epoch 171/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2986 - accuracy: 0.8659 - val_loss: 0.2902 - val_accuracy: 0.8741\n",
            "Epoch 172/250\n",
            "32/32 [==============================] - 3s 102ms/step - loss: 0.3169 - accuracy: 0.8463 - val_loss: 0.3171 - val_accuracy: 0.8878\n",
            "Epoch 173/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3224 - accuracy: 0.8422 - val_loss: 0.2940 - val_accuracy: 0.8878\n",
            "Epoch 174/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2993 - accuracy: 0.8674 - val_loss: 0.2991 - val_accuracy: 0.8912\n",
            "Epoch 175/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2959 - accuracy: 0.8442 - val_loss: 0.3189 - val_accuracy: 0.8878\n",
            "Epoch 176/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3335 - accuracy: 0.8427 - val_loss: 0.3194 - val_accuracy: 0.8810\n",
            "Epoch 177/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3056 - accuracy: 0.8662 - val_loss: 0.2835 - val_accuracy: 0.8844\n",
            "Epoch 178/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2837 - accuracy: 0.8698 - val_loss: 0.2781 - val_accuracy: 0.8946\n",
            "Epoch 179/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3335 - accuracy: 0.8633 - val_loss: 0.2974 - val_accuracy: 0.8946\n",
            "Epoch 180/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3077 - accuracy: 0.8500 - val_loss: 0.2962 - val_accuracy: 0.8946\n",
            "Epoch 181/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2999 - accuracy: 0.8567 - val_loss: 0.2998 - val_accuracy: 0.8980\n",
            "Epoch 182/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2597 - accuracy: 0.8980 - val_loss: 0.3106 - val_accuracy: 0.8878\n",
            "Epoch 183/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3246 - accuracy: 0.8567 - val_loss: 0.3247 - val_accuracy: 0.8810\n",
            "Epoch 184/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3117 - accuracy: 0.8684 - val_loss: 0.3299 - val_accuracy: 0.8707\n",
            "Epoch 185/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3084 - accuracy: 0.8369 - val_loss: 0.3043 - val_accuracy: 0.8741\n",
            "Epoch 186/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3101 - accuracy: 0.8499 - val_loss: 0.3217 - val_accuracy: 0.8673\n",
            "Epoch 187/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3168 - accuracy: 0.8412 - val_loss: 0.3029 - val_accuracy: 0.8946\n",
            "Epoch 188/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3148 - accuracy: 0.8597 - val_loss: 0.2874 - val_accuracy: 0.8980\n",
            "Epoch 189/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2951 - accuracy: 0.8597 - val_loss: 0.3095 - val_accuracy: 0.8741\n",
            "Epoch 190/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3002 - accuracy: 0.8714 - val_loss: 0.3040 - val_accuracy: 0.8912\n",
            "Epoch 191/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3096 - accuracy: 0.8601 - val_loss: 0.2990 - val_accuracy: 0.8912\n",
            "Epoch 192/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2721 - accuracy: 0.8850 - val_loss: 0.2939 - val_accuracy: 0.8810\n",
            "Epoch 193/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2800 - accuracy: 0.8750 - val_loss: 0.3105 - val_accuracy: 0.8844\n",
            "Epoch 194/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2894 - accuracy: 0.8749 - val_loss: 0.3102 - val_accuracy: 0.8776\n",
            "Epoch 195/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2814 - accuracy: 0.8719 - val_loss: 0.3478 - val_accuracy: 0.8537\n",
            "Epoch 196/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3145 - accuracy: 0.8527 - val_loss: 0.3240 - val_accuracy: 0.8776\n",
            "Epoch 197/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3016 - accuracy: 0.8625 - val_loss: 0.3027 - val_accuracy: 0.8776\n",
            "Epoch 198/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2813 - accuracy: 0.8827 - val_loss: 0.3119 - val_accuracy: 0.8707\n",
            "Epoch 199/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2940 - accuracy: 0.8779 - val_loss: 0.2927 - val_accuracy: 0.8912\n",
            "Epoch 200/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2775 - accuracy: 0.8848 - val_loss: 0.3131 - val_accuracy: 0.8707\n",
            "Epoch 201/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3095 - accuracy: 0.8587 - val_loss: 0.3128 - val_accuracy: 0.8912\n",
            "Epoch 202/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2506 - accuracy: 0.8725 - val_loss: 0.2980 - val_accuracy: 0.8844\n",
            "Epoch 203/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2744 - accuracy: 0.8793 - val_loss: 0.3298 - val_accuracy: 0.8844\n",
            "Epoch 204/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3079 - accuracy: 0.8702 - val_loss: 0.2878 - val_accuracy: 0.8810\n",
            "Epoch 205/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3059 - accuracy: 0.8606 - val_loss: 0.3071 - val_accuracy: 0.8741\n",
            "Epoch 206/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2712 - accuracy: 0.8711 - val_loss: 0.2955 - val_accuracy: 0.8776\n",
            "Epoch 207/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2630 - accuracy: 0.8784 - val_loss: 0.3068 - val_accuracy: 0.8605\n",
            "Epoch 208/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2728 - accuracy: 0.8869 - val_loss: 0.3003 - val_accuracy: 0.8810\n",
            "Epoch 209/250\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.2502 - accuracy: 0.8966 - val_loss: 0.2972 - val_accuracy: 0.8946\n",
            "Epoch 210/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2912 - accuracy: 0.8751 - val_loss: 0.2964 - val_accuracy: 0.8810\n",
            "Epoch 211/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.2515 - accuracy: 0.8996 - val_loss: 0.3143 - val_accuracy: 0.8707\n",
            "Epoch 212/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2988 - accuracy: 0.8619 - val_loss: 0.3068 - val_accuracy: 0.8741\n",
            "Epoch 213/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2874 - accuracy: 0.8717 - val_loss: 0.2968 - val_accuracy: 0.8878\n",
            "Epoch 214/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2797 - accuracy: 0.8756 - val_loss: 0.3045 - val_accuracy: 0.8776\n",
            "Epoch 215/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2636 - accuracy: 0.8815 - val_loss: 0.2931 - val_accuracy: 0.8776\n",
            "Epoch 216/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3035 - accuracy: 0.8549 - val_loss: 0.2839 - val_accuracy: 0.8844\n",
            "Epoch 217/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2652 - accuracy: 0.8704 - val_loss: 0.3367 - val_accuracy: 0.8810\n",
            "Epoch 218/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2482 - accuracy: 0.8986 - val_loss: 0.2854 - val_accuracy: 0.8912\n",
            "Epoch 219/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2804 - accuracy: 0.8835 - val_loss: 0.3184 - val_accuracy: 0.8810\n",
            "Epoch 220/250\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3239 - accuracy: 0.8573 - val_loss: 0.3066 - val_accuracy: 0.8912\n",
            "Epoch 221/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2730 - accuracy: 0.8767 - val_loss: 0.2842 - val_accuracy: 0.8946\n",
            "Epoch 222/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2707 - accuracy: 0.8916 - val_loss: 0.3299 - val_accuracy: 0.8810\n",
            "Epoch 223/250\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3433 - accuracy: 0.8406 - val_loss: 0.3023 - val_accuracy: 0.8844\n",
            "Epoch 224/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.3010 - accuracy: 0.8702 - val_loss: 0.3033 - val_accuracy: 0.8707\n",
            "Epoch 225/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2664 - accuracy: 0.8879 - val_loss: 0.3113 - val_accuracy: 0.8741\n",
            "Epoch 226/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2980 - accuracy: 0.8580 - val_loss: 0.3232 - val_accuracy: 0.8776\n",
            "Epoch 227/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3185 - accuracy: 0.8671 - val_loss: 0.2911 - val_accuracy: 0.9082\n",
            "Epoch 228/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2746 - accuracy: 0.8882 - val_loss: 0.2950 - val_accuracy: 0.8946\n",
            "Epoch 229/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2961 - accuracy: 0.8537 - val_loss: 0.2969 - val_accuracy: 0.8844\n",
            "Epoch 230/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2573 - accuracy: 0.8723 - val_loss: 0.2751 - val_accuracy: 0.9116\n",
            "Epoch 231/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2652 - accuracy: 0.8813 - val_loss: 0.2870 - val_accuracy: 0.8946\n",
            "Epoch 232/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2845 - accuracy: 0.8673 - val_loss: 0.3486 - val_accuracy: 0.8673\n",
            "Epoch 233/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3609 - accuracy: 0.8533 - val_loss: 0.3277 - val_accuracy: 0.8810\n",
            "Epoch 234/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.3098 - accuracy: 0.8541 - val_loss: 0.2973 - val_accuracy: 0.8946\n",
            "Epoch 235/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2837 - accuracy: 0.8846 - val_loss: 0.3050 - val_accuracy: 0.8810\n",
            "Epoch 236/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2723 - accuracy: 0.8854 - val_loss: 0.2797 - val_accuracy: 0.9014\n",
            "Epoch 237/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2893 - accuracy: 0.8661 - val_loss: 0.2927 - val_accuracy: 0.8912\n",
            "Epoch 238/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2664 - accuracy: 0.8773 - val_loss: 0.3295 - val_accuracy: 0.8776\n",
            "Epoch 239/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3023 - accuracy: 0.8654 - val_loss: 0.2831 - val_accuracy: 0.8946\n",
            "Epoch 240/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2654 - accuracy: 0.8862 - val_loss: 0.3040 - val_accuracy: 0.9014\n",
            "Epoch 241/250\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.2956 - accuracy: 0.8657 - val_loss: 0.3243 - val_accuracy: 0.8878\n",
            "Epoch 242/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2563 - accuracy: 0.8940 - val_loss: 0.3225 - val_accuracy: 0.8810\n",
            "Epoch 243/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2529 - accuracy: 0.8900 - val_loss: 0.2792 - val_accuracy: 0.8980\n",
            "Epoch 244/250\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.2294 - accuracy: 0.8999 - val_loss: 0.2864 - val_accuracy: 0.8946\n",
            "Epoch 245/250\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.2890 - accuracy: 0.8744 - val_loss: 0.2841 - val_accuracy: 0.8912\n",
            "Epoch 246/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2765 - accuracy: 0.8947 - val_loss: 0.2883 - val_accuracy: 0.9014\n",
            "Epoch 247/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2968 - accuracy: 0.8762 - val_loss: 0.2976 - val_accuracy: 0.8980\n",
            "Epoch 248/250\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.2483 - accuracy: 0.8882 - val_loss: 0.3093 - val_accuracy: 0.8810\n",
            "Epoch 249/250\n",
            "32/32 [==============================] - 3s 91ms/step - loss: 0.2374 - accuracy: 0.8957 - val_loss: 0.2937 - val_accuracy: 0.8844\n",
            "Epoch 250/250\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.2586 - accuracy: 0.8880 - val_loss: 0.2931 - val_accuracy: 0.8946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "32rKbdtmOT15",
        "outputId": "bcb4721b-5732-439e-a9f2-6a678e0258ee"
      },
      "source": [
        "def plot_graphs(history, string):\r\n",
        "  plt.plot(history.history[string])\r\n",
        "  plt.plot(history.history['val_'+string])\r\n",
        "  plt.xlabel(\"Epochs\")\r\n",
        "  plt.ylabel(string)\r\n",
        "  plt.legend([string, 'val_'+string])\r\n",
        "  plt.ylim([0,1])\r\n",
        "  plt.grid()\r\n",
        "  plt.show()\r\n",
        "  \r\n",
        "plot_graphs(history, \"accuracy\")\r\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bQcLoc0j20Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884e59b5-f78f-46a5-a5bc-9494a452530e"
      },
      "source": [
        "results = model.evaluate([x_test, x_angle_test], y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3038 - accuracy: 0.8919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSfS-ypxtEOu"
      },
      "source": [
        "That looks good, so save the model in our drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCfeXA1atKOT",
        "outputId": "b33fdb58-e79b-430f-b4eb-72c08ab5fa91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.save(\"/concent/drive/MyDrive/Iceberg_Ship_Classification/model_inc_angle.hd5\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /concent/drive/MyDrive/Iceberg_Ship_Classification/model_inc_angle.hd5/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}